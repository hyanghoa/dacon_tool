{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55c79ae4-2c18-45f1-9607-e9f49a43119b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ea90d00-c161-42ee-afd8-387151307817",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "import logging.config\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.transformer import _get_activation_fn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, Sampler\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.ops import FeaturePyramidNetwork, DeformConv2d\n",
    "\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from RandAugment import RandAugment\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import torch_optimizer as optim\n",
    "import ttach as tta\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "from robust_loss_pytorch import AdaptiveLossFunction\n",
    "import robust_loss_pytorch\n",
    "\n",
    "import neptune.new as neptune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b9a38c-12cb-4b43-b008-3fb2dfcb0b69",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22a675ab-087c-477c-9085-e910f7a617c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/djlee/dacon-growing/e/DAC-409\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "neptune_run = neptune.init(\n",
    "    project=\"djlee/dacon-growing\",\n",
    "    api_token=os.environ[\"NEPTUNE_API_TOKEN\"],\n",
    ")\n",
    "\n",
    "params = {\n",
    "    \"model_name\": \"tf_efficientnetv2_b0\",\n",
    "    \"optimizer\": \"sgd_sam\",\n",
    "    \"criterion\": \"l1\",\n",
    "    \"huber_delta\": 0,\n",
    "    \"scheduler\": \"cosineannealinglr\",\n",
    "    \"num_class\": 1,\n",
    "    \"epochs\": 25,\n",
    "    \"batch\": 64,\n",
    "    \"learning_rate\": 16e-2,\n",
    "    \"weight_decay\": 5e-2,\n",
    "    \"drop_out_rate\": 0.4,\n",
    "    \"drop_path_rate\": 0.15,\n",
    "    \"max_norm\": 1,\n",
    "    \"num_workers\": 10,\n",
    "    \"train_image_size\": (224, 224),\n",
    "    \"test_image_size\": (224, 224),\n",
    "    \"ib_start_epoch\": 9999,\n",
    "    \"cutmix\": False,\n",
    "    \"mixup\": False,\n",
    "    \"mixup_alpha\": 0.2,\n",
    "    \"mix_end_epoch\": -1,\n",
    "    \"seed\": 42,\n",
    "    \"scaler\": \"RobustScaler\",\n",
    "    \n",
    "    # LSTM\n",
    "    # \"lstm_input_size\": 18,\n",
    "    # \"lstm_hidden_size\": 64,\n",
    "    # \"lstm_num_layers\": 2,\n",
    "    # \"lstm_bidirectional\": True,\n",
    "    # \"lstm_batch_first\": True,\n",
    "}\n",
    "\n",
    "neptune_run[\"parameters\"] = params\n",
    "\n",
    "TRAIN_PATH = \"data/train/\"\n",
    "TEST_PATH = \"data/test/\"\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "SAVE_PATH = f\"models/{params['model_name']}_{datetime.datetime.now().strftime('%y-%m-%d-%H:%M:%S')}/\"\n",
    "os.makedirs(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ab3f9a-b318-44e9-9bbd-4daca235ff2c",
   "metadata": {},
   "source": [
    "# Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a50757d-a3f0-43d3-b102-67c75a7619c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-20 16:46:15] {'model_name': 'tf_efficientnetv2_b0', 'optimizer': 'sgd_sam', 'criterion': 'l1', 'huber_delta': 0, 'scheduler': 'cosineannealinglr', 'num_class': 1, 'epochs': 25, 'batch': 64, 'learning_rate': 0.16, 'weight_decay': 0.05, 'drop_out_rate': 0.4, 'drop_path_rate': 0.15, 'max_norm': 1, 'num_workers': 10, 'train_image_size': (224, 224), 'test_image_size': (224, 224), 'ib_start_epoch': 9999, 'cutmix': False, 'mixup': False, 'mixup_alpha': 0.2, 'mix_end_epoch': -1, 'seed': 42, 'scaler': 'RobustScaler'}\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"version\": 1,\n",
    "    \"formatters\": {\n",
    "        \"simple\": {\"format\": \"[%(asctime)s] %(message)s\", \"datefmt\": \"%Y-%m-%d %H:%M:%S\"},\n",
    "    },\n",
    "    \"handlers\": {\n",
    "        \"console\": {\n",
    "            \"class\": \"logging.StreamHandler\",\n",
    "            \"formatter\": \"simple\",\n",
    "            \"level\": \"INFO\",\n",
    "        },\n",
    "        \"file\": {\n",
    "            \"class\": \"logging.FileHandler\",\n",
    "            \"filename\": f\"{SAVE_PATH}/train.log\",\n",
    "            \"formatter\": \"simple\",\n",
    "            \"level\": \"INFO\",\n",
    "        },\n",
    "    },\n",
    "    \"root\": {\"handlers\": [\"console\", \"file\"], \"level\": \"INFO\"},\n",
    "    \"loggers\": {\"parent\": {\"level\": \"INFO\"}, \"parent.child\": {\"level\": \"DEBUG\"},},\n",
    "}\n",
    "\n",
    "logging.config.dictConfig(config)\n",
    "logger = logging.getLogger()\n",
    "logger.info(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14943bc2-1981-4b6d-9422-aca19ec7961a",
   "metadata": {},
   "source": [
    "# Fix Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "431d1e6d-8664-436c-95c8-c66eba335969",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(params[\"seed\"])\n",
    "np.random.seed(params[\"seed\"])\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(params[\"seed\"])\n",
    "torch.manual_seed(params[\"seed\"])\n",
    "torch.cuda.manual_seed(params[\"seed\"])\n",
    "torch.backends.cudnn.deterministic = False  # True 할 시 연산속도 감소. 마지막에 고정시킬 때 사용 권장.\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ea0c05-db43-4aa7-b607-d4b56be81231",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31c203d-052e-41e9-8728-46ba5642fd40",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Mean, Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbf29174-f3ec-4bcd-9f7f-8e3debcef07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnlineMeanStd:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, dataset, batch_size, method='strong', mode=\"train\"):\n",
    "        \"\"\"\n",
    "        Calculate mean and std of a dataset in lazy mode (online)\n",
    "        On mode strong, batch size will be discarded because we use batch_size=1 to minimize leaps.\n",
    "        :param dataset: Dataset object corresponding to your dataset\n",
    "        :param batch_size: higher size, more accurate approximation\n",
    "        :param method: weak: fast but less accurate, strong: slow but very accurate - recommended = strong\n",
    "        :return: A tuple of (mean, std) with size of (3,)\n",
    "        \"\"\"\n",
    "\n",
    "        if method == 'weak':\n",
    "            loader = DataLoader(dataset=dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False,\n",
    "                                num_workers=1,\n",
    "                                pin_memory=0)\n",
    "            mean = 0.\n",
    "            std = 0.\n",
    "            nb_samples = 0.\n",
    "            for data in loader:\n",
    "                data = data[0]\n",
    "                batch_samples = data.size(0)\n",
    "                data = data.view(batch_samples, data.size(1), -1)\n",
    "                mean += data.mean(2).sum(0)\n",
    "                std += data.std(2).sum(0)\n",
    "                nb_samples += batch_samples\n",
    "\n",
    "            mean /= nb_samples\n",
    "            std /= nb_samples\n",
    "\n",
    "            return mean, std\n",
    "\n",
    "        elif method == 'strong':\n",
    "            loader = DataLoader(dataset=dataset,\n",
    "                                batch_size=1,\n",
    "                                shuffle=False,\n",
    "                                num_workers=1,\n",
    "                                pin_memory=0)\n",
    "            cnt = 0\n",
    "            fst_moment = torch.empty(3)\n",
    "            snd_moment = torch.empty(3)\n",
    "\n",
    "            for data in loader:\n",
    "                if mode == \"train\":\n",
    "                    data = data[0] # train -> data[0] / test -> data\n",
    "                elif mode == \"test\":\n",
    "                    data = data\n",
    "                b, c, h, w = data.shape\n",
    "                nb_pixels = b * h * w\n",
    "                sum_ = torch.sum(data, dim=[0, 2, 3])\n",
    "                sum_of_square = torch.sum(data ** 2, dim=[0, 2, 3])\n",
    "                fst_moment = (cnt * fst_moment + sum_) / (cnt + nb_pixels)\n",
    "                snd_moment = (cnt * snd_moment + sum_of_square) / (cnt + nb_pixels)\n",
    "\n",
    "                cnt += nb_pixels\n",
    "\n",
    "            return fst_moment, torch.sqrt(snd_moment - fst_moment ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f937d59-e03e-4b92-b7af-8f2a0d759b16",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68df44ee-d2a5-4952-8de0-ebcae1302884",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 df,\n",
    "                 mode,\n",
    "                 transform,\n",
    "                 scaler,\n",
    "                 imputer,\n",
    "                 mean=[0.485, 0.456, 0.406],\n",
    "                 std=[0.229, 0.224, 0.225]):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.scaler = scaler\n",
    "        self.imputer = imputer\n",
    "        self.data_list = df\n",
    "            \n",
    "    def __len__(self):\n",
    "        if self.mode == \"train\":\n",
    "            return len(self.data_list)\n",
    "        elif self.mode == \"test\":\n",
    "            return len(self.data_list[0])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == \"train\":\n",
    "            image = cv2.imread(self.data_list[index][0])\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            label = np.array(self.data_list[index][2]).astype(np.float32)\n",
    "            image = self.transform(image)[\"image\"]\n",
    "            meta = pd.read_csv(self.data_list[index][1])\n",
    "            meta.drop([\"시간\"], axis=1, inplace=True)\n",
    "            meta.interpolate(inplace=True)\n",
    "            meta = self.imputer.transform(meta)\n",
    "            meta = self.scaler.transform(meta)\n",
    "            # meta = meta.mean(axis=1)\n",
    "            return image, torch.from_numpy(meta), torch.from_numpy(label)\n",
    "\n",
    "        elif self.mode == \"test\":\n",
    "            image = cv2.imread(self.data_list[0][index])\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = self.transform(image)[\"image\"]\n",
    "            meta = pd.read_csv(self.data_list[1][index])\n",
    "            meta.drop([\"시간\"], axis=1, inplace=True)\n",
    "            meta.interpolate(inplace=True)\n",
    "            meta = self.imputer.transform(meta)\n",
    "            meta = self.scaler.transform(meta)\n",
    "            # meta = meta.mean(axis=1)\n",
    "            return image, torch.from_numpy(meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b466d3e-487d-4b01-a440-acbbc0637d04",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d984b93a-66c6-4c98-8731-beb93b817dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCycleIter:\n",
    "    \n",
    "    def __init__ (self, data, test_mode=False):\n",
    "        self.data_list = list(data)\n",
    "        self.length = len(self.data_list)\n",
    "        self.i = self.length - 1\n",
    "        self.test_mode = test_mode\n",
    "        \n",
    "    def __iter__ (self):\n",
    "        return self\n",
    "    \n",
    "    def __next__ (self):\n",
    "        self.i += 1\n",
    "        \n",
    "        if self.i == self.length:\n",
    "            self.i = 0\n",
    "            if not self.test_mode:\n",
    "                random.shuffle(self.data_list)\n",
    "            \n",
    "        return self.data_list[self.i]\n",
    "    \n",
    "def class_aware_sample_generator (cls_iter, data_iter_list, n, num_samples_cls=1, is_infinite=False):\n",
    "\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i < n or is_infinite:\n",
    "        \n",
    "        if j >= num_samples_cls:\n",
    "            j = 0\n",
    "    \n",
    "        if j == 0:\n",
    "            temp_tuple = next(zip(*[data_iter_list[next(cls_iter)]]*num_samples_cls))\n",
    "            yield temp_tuple[j]\n",
    "        else:\n",
    "            yield temp_tuple[j]\n",
    "        \n",
    "        i += 1\n",
    "        j += 1\n",
    "\n",
    "class ClassAwareSampler (Sampler):\n",
    "    \n",
    "    def __init__(self, data_source, num_samples_cls=1, is_infinite=False):\n",
    "        num_classes = len(np.unique(data_source.labels))\n",
    "        self.class_iter = RandomCycleIter(range(num_classes))\n",
    "        cls_data_list = [list() for _ in range(num_classes)]\n",
    "        for i, label in enumerate(data_source.labels):\n",
    "            cls_data_list[label].append(i)\n",
    "        self.data_iter_list = [RandomCycleIter(x) for x in cls_data_list]\n",
    "        self.num_samples = max([len(x) for x in cls_data_list]) * len(cls_data_list)\n",
    "        self.num_samples_cls = num_samples_cls\n",
    "\n",
    "        self.is_infinite = is_infinite\n",
    "        \n",
    "    def __iter__ (self):\n",
    "        return class_aware_sample_generator(self.class_iter, self.data_iter_list,\n",
    "                                            self.num_samples, self.num_samples_cls, self.is_infinite)\n",
    "    \n",
    "    def __len__ (self):\n",
    "        return self.num_samples\n",
    "    \n",
    "def get_sampler():\n",
    "    return ClassAwareSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9daded-7e85-4fcb-af96-5c93589f9be8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b8a86c-6711-4545-abf0-e8ff99bd06b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cosine CrossEntropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41c477ca-97a5-41b0-a5a1-98b45ed77d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, xent=.1, reduction=\"mean\", weight=None):\n",
    "        super(CosineCrossEntropyLoss, self).__init__()\n",
    "        self.xent = xent\n",
    "        self.reduction = reduction\n",
    "        self.weight = weight\n",
    "        self.y = torch.Tensor([1]).cuda()\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        cosine_loss = F.cosine_embedding_loss(input, F.one_hot(target, num_classes=input.size(-1)), self.y, reduction=self.reduction)\n",
    "        cent_loss = F.cross_entropy(F.normalize(input), target, reduction=self.reduction, weight=self.weight)\n",
    "        \n",
    "        return cosine_loss + self.xent * cent_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4943a11-7aff-42e9-ae79-443e0412e88b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cosine Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e8b23c7-65ff-4668-83a1-3eca238cbc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalCosineLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2, xent=.1, reduction=\"mean\", weight=None):\n",
    "        super(FocalCosineLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.xent = xent\n",
    "        self.y = torch.Tensor([1]).cuda()\n",
    "        self.reduction = reduction\n",
    "        self.weight = weight\n",
    "\n",
    "    def forward(self, input, target, reduction=\"mean\"):\n",
    "        cosine_loss = F.cosine_embedding_loss(input, F.one_hot(target, num_classes=input.size(-1)), self.y, reduction=self.reduction)\n",
    "\n",
    "        cent_loss = F.cross_entropy(F.normalize(input), target, reduction=self.reduction, weight=self.weight)\n",
    "        pt = torch.exp(-cent_loss)\n",
    "        focal_loss = self.alpha * (1-pt)**self.gamma * cent_loss\n",
    "\n",
    "        if self.reduction == \"mean\":\n",
    "            focal_loss = torch.mean(focal_loss)\n",
    "\n",
    "        return cosine_loss + self.xent * focal_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace1ffa2-23a8-4c1f-90b4-18322512cde9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Seesaw Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fbd0ffd-8f1e-423d-a3e8-776d7b9a9fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeesawLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of seesaw loss.\n",
    "    Refers to `Seesaw Loss for Long-Tailed Instance Segmentation (CVPR 2021)\n",
    "    <https://arxiv.org/abs/2008.10032>\n",
    "    Args:\n",
    "        num_classes (int): The number of classes.\n",
    "                Default to 1000 for the ImageNet dataset.\n",
    "        p (float): The ``p`` in the mitigation factor.\n",
    "                Defaults to 0.8.\n",
    "        q (float): The ``q`` in the compensation factor.\n",
    "                Defaults to 2.0.\n",
    "        eps (float): The min divisor to smooth the computation of compensation factor.\n",
    "                Default to 1e-2.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=params[\"num_class\"],\n",
    "                 p=0.8, q=1.0, eps=1e-2):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "        self.eps = eps\n",
    "\n",
    "        # cumulative samples for each category\n",
    "        self.register_buffer('accumulated',\n",
    "                             torch.zeros(self.num_classes, dtype=torch.float))\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        # accumulate the samples for each category\n",
    "        for unique in targets.unique():\n",
    "            self.accumulated[unique] += (targets == unique.item()).sum()\n",
    "\n",
    "        onehot_targets = F.one_hot(targets, self.num_classes)\n",
    "        seesaw_weights = outputs.new_ones(onehot_targets.size())\n",
    "\n",
    "        # mitigation factor\n",
    "        if self.p > 0:\n",
    "            matrix = self.accumulated[None, :].clamp(min=1) / self.accumulated[:, None].clamp(min=1)\n",
    "            index = (matrix < 1.0).float()\n",
    "            sample_weights = matrix.pow(self.p) * index + (1 - index)\n",
    "            mitigation_factor = sample_weights[targets.long(), :]\n",
    "            seesaw_weights = seesaw_weights * mitigation_factor\n",
    "\n",
    "        # compensation factor\n",
    "        if self.q > 0:\n",
    "            scores = F.softmax(outputs.detach(), dim=1)\n",
    "            self_scores = scores[torch.arange(0, len(scores)).to(scores.device).long(), targets.long()]\n",
    "            score_matrix = scores / self_scores[:, None].clamp(min=self.eps)\n",
    "            index = (score_matrix > 1.0).float()\n",
    "            compensation_factor = score_matrix.pow(self.q) * index + (1 - index)\n",
    "            seesaw_weights = seesaw_weights * compensation_factor\n",
    "\n",
    "        outputs = outputs + (seesaw_weights.log() * (1 - onehot_targets))\n",
    "        return F.cross_entropy(outputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4197eec6-3cb5-49c6-9552-7658cd5d55d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebfce20a-2a36-4d85-b2c7-ae7107b5585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, label_smoothing=0.1, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = nn.CrossEntropyLoss(label_smoothing=self.label_smoothing)(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf8b9d1-d4a7-4fbd-ba53-4683bc74e97e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CDB Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "797f7eab-3be2-4fc0-895a-2419df5403ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return (1/(1+np.exp(-x)))\n",
    "\n",
    "class CDB_loss(nn.Module):\n",
    "  \n",
    "    def __init__(self, class_difficulty, tau='dynamic', reduction='none'):\n",
    "        \n",
    "        super(CDB_loss, self).__init__()\n",
    "        self.class_difficulty = class_difficulty\n",
    "        if tau == 'dynamic':\n",
    "            bias = (1 - np.min(class_difficulty))/(1 - np.max(class_difficulty) + 0.01)\n",
    "            tau = sigmoid(bias)\n",
    "        else:\n",
    "            tau = float(tau) \n",
    "        self.weights = self.class_difficulty ** tau\n",
    "        self.weights = self.weights / self.weights.sum() * len(self.weights)\n",
    "        self.reduction = reduction\n",
    "        self.loss = nn.CrossEntropyLoss(weight=torch.FloatTensor(self.weights), reduction=self.reduction).cuda()\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        return self.loss(input, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb758fd-4dbe-4a7d-93f5-09dc41a56a70",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CB Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d501d9e-0a8e-4501-8862-bb01461f60df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CB_loss(labels, logits, samples_per_cls, no_of_classes, loss_type, beta, gamma, device):\n",
    "    effective_num = 1.0 - np.power(beta, samples_per_cls)\n",
    "    weights = (1.0 - beta) / np.array(effective_num)\n",
    "    weights = weights / np.sum(weights) * no_of_classes\n",
    "\n",
    "    labels_one_hot = F.one_hot(labels, no_of_classes).float()\n",
    "    labels_one_hot = labels_one_hot.to(device)\n",
    "\n",
    "    weights = torch.tensor(weights).float()\n",
    "    weights = weights.unsqueeze(0)\n",
    "    weights = weights.repeat(labels_one_hot.shape[0],1).to(device)\n",
    "    weights = weights* labels_one_hot\n",
    "    weights = weights.sum(1)\n",
    "    weights = weights.unsqueeze(1)\n",
    "    weights = weights.repeat(1,no_of_classes)\n",
    "\n",
    "    if loss_type == \"focal\":\n",
    "        cb_loss = focal_loss(labels_one_hot, logits, weights, gamma)\n",
    "    elif loss_type == \"sigmoid\":\n",
    "        cb_loss = F.binary_cross_entropy_with_logits(input = logits,target = labels_one_hot, weights = weights)\n",
    "    elif loss_type == \"softmax\":\n",
    "        pred = logits.softmax(dim = 1)\n",
    "        cb_loss = F.binary_cross_entropy(input = pred, target = labels_one_hot, weight = weights)\n",
    "    return cb_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac45901-e9f0-4524-81b2-9c0221c238da",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Equalized Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ba620ec-512f-4ec9-8e67-bd67cae53058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalized_focal_loss(logits,\n",
    "                         targets,\n",
    "                         gamma_b=2,\n",
    "                         scale_factor=8,\n",
    "                         reduction=\"mean\"):\n",
    "    \"\"\" EFL loss\"\"\"\n",
    "    ce_loss = F.cross_entropy(logits, targets, reduction=\"none\", label_smoothing=0.1)\n",
    "    outputs = F.cross_entropy(logits, targets, label_smoothing=0.1)\n",
    "    log_pt = -ce_loss\n",
    "    pt = torch.exp(log_pt)\n",
    "\n",
    "    targets = targets.view(-1, 1)\n",
    "    grad_i = torch.autograd.grad(outputs=-outputs, inputs=logits)[0]\n",
    "    grad_i = grad_i.gather(1, targets)\n",
    "    pos_grad_i = F.relu(grad_i).sum()\n",
    "    neg_grad_i = F.relu(-grad_i).sum()\n",
    "    neg_grad_i += 1e-9\n",
    "    grad_i = pos_grad_i / neg_grad_i\n",
    "    grad_i = torch.clamp(grad_i, min=0, max=1)\n",
    "\n",
    "    dy_gamma = gamma_b + scale_factor * (1 - grad_i)\n",
    "    dy_gamma = dy_gamma.view(-1)\n",
    "    # weighting factor\n",
    "    wf = dy_gamma / gamma_b\n",
    "    weights = wf * (1 - pt) ** dy_gamma\n",
    "\n",
    "    efl = weights * ce_loss\n",
    "\n",
    "    if reduction == \"sum\":\n",
    "        efl = efl.sum()\n",
    "    elif reduction == \"mean\":\n",
    "        efl = efl.mean()\n",
    "    else:\n",
    "        raise ValueError(f\"reduction '{reduction}' is not valid\")\n",
    "    return efl\n",
    "\n",
    "\n",
    "def balanced_equalized_focal_loss(logits,\n",
    "                                  targets,\n",
    "                                  alpha_t=0.25,\n",
    "                                  gamma_b=2,\n",
    "                                  scale_factor=8,\n",
    "                                  reduction=\"mean\"):\n",
    "    \"\"\"balanced EFL loss\"\"\"\n",
    "    return alpha_t * equalized_focal_loss(logits, targets, gamma_b,\n",
    "                                          scale_factor, reduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd5b988-bc5a-4a5c-8926-14893de92309",
   "metadata": {
    "tags": []
   },
   "source": [
    "### IB Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84f6a4ed-f82b-4a9d-8f13-fe40752bd735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ib_loss(input_values, ib):\n",
    "    \"\"\"Computes the focal loss\"\"\"\n",
    "    loss = input_values * ib\n",
    "    return loss.mean()\n",
    "\n",
    "class IBLoss(nn.Module):\n",
    "    def __init__(self, weight=None, alpha=10000.):\n",
    "        super(IBLoss, self).__init__()\n",
    "        assert alpha > 0\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = 0.001\n",
    "        self.weight = weight\n",
    "\n",
    "    def forward(self, outputs, target):\n",
    "        input, features = outputs\n",
    "        grads = torch.sum(torch.abs(F.softmax(input, dim=1) - F.one_hot(target, NUM_CLASS)),1) # N * 1\n",
    "        ib = grads*features.reshape(-1)\n",
    "        ib = self.alpha / (ib + self.epsilon)\n",
    "        return ib_loss(F.cross_entropy(input, target, reduction='none', weight=self.weight), ib)\n",
    "\n",
    "\n",
    "def ib_focal_loss(input_values, ib, gamma):\n",
    "    \"\"\"Computes the ib focal loss\"\"\"\n",
    "    p = torch.exp(-input_values)\n",
    "    loss = (1 - p) ** gamma * input_values * ib\n",
    "    return loss.mean()\n",
    "\n",
    "class IB_FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None, alpha=10000., gamma=0.):\n",
    "        super(IB_FocalLoss, self).__init__()\n",
    "        assert alpha > 0\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = 0.001\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, outputs, target):\n",
    "        input, features = outputs\n",
    "        grads = torch.sum(torch.abs(F.softmax(input, dim=1) - F.one_hot(target, NUM_CLASS)),1) # N * 1\n",
    "        ib = grads*(features.reshape(-1))\n",
    "        ib = self.alpha / (ib + self.epsilon)\n",
    "        return ib_focal_loss(F.cross_entropy(input, target, reduction='none', weight=self.weight), ib, self.gamma) # weight=self.weight\n",
    "    \n",
    "    \n",
    "class IB_CosineFocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None, alpha=10000., gamma=0.):\n",
    "        super(IB_CosineFocalLoss, self).__init__()\n",
    "        assert alpha > 0\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = 0.001\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, outputs, target):\n",
    "        input, features = outputs\n",
    "        grads = torch.sum(torch.abs(F.softmax(input, dim=1) - F.one_hot(target, NUM_CLASS)),1) # N * 1\n",
    "        ib = grads*(features.reshape(-1))\n",
    "        ib = self.alpha / (ib + self.epsilon)\n",
    "        cosine_ce = CosineCrossEntropyLoss(reduction='none', weight=self.weight).cuda()\n",
    "        return ib_focal_loss(cosine_ce(input, target), ib, self.gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f573c0a3-c4c7-4781-9fc8-15e552fbbc5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Smooth Crossentropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "088c6dbc-72ca-4851-b822-e01f76e3b727",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothCrossentropy(nn.Module):\n",
    "    def __init__(self, smoothing=0.1):\n",
    "        super(SmoothCrossentropy, self).__init__()\n",
    "        self.smoothing=smoothing\n",
    "\n",
    "    def forward(self, pred, gold):\n",
    "        n_class = pred.size(1)\n",
    "\n",
    "        one_hot = torch.full_like(pred, fill_value=self.smoothing / (n_class - 1))\n",
    "        one_hot.scatter_(dim=1, index=gold.unsqueeze(1), value=1.0 - self.smoothing)\n",
    "        log_prob = F.log_softmax(pred, dim=1)\n",
    "\n",
    "        return F.kl_div(input=log_prob, target=one_hot, reduction='none').sum(-1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec02d0ed-952f-4ea9-abc1-a12a4f1779a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Blanced Softmax Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a2ee450-199d-47cb-b615-1d3dbd813a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedSoftmax(nn.Module):\n",
    "    \"\"\"\n",
    "    Balanced Softmax Loss\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(BalancedSoftmax, self).__init__()\n",
    "\n",
    "    def forward(self, input, label, reduction='mean'):\n",
    "        return balanced_softmax_loss(input, label, reduction)\n",
    "\n",
    "\n",
    "def balanced_softmax_loss(logits, labels, reduction=\"mean\", weight=None):\n",
    "    spc = torch.cuda.FloatTensor(SAMPLES_PER_CLS)\n",
    "    spc = spc.unsqueeze(0).expand(logits.shape[0], -1)\n",
    "    logits = logits + spc.log()\n",
    "    loss = F.cross_entropy(input=logits, target=labels, reduction=reduction, label_smoothing=0.1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02acfbca-763a-4f0d-9fc1-3dd2cb79cfa8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ASL loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd4f79f8-1a09-4932-861a-787b3aa1e496",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASLSingleLabel(nn.Module):\n",
    "    '''\n",
    "    This loss is intended for single-label classification problems\n",
    "    '''\n",
    "    def __init__(self, gamma_pos=0, gamma_neg=4, eps=0.1, reduction='mean'):\n",
    "        super(ASLSingleLabel, self).__init__()\n",
    "\n",
    "        self.eps = eps\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=-1)\n",
    "        self.targets_classes = []\n",
    "        self.gamma_pos = gamma_pos\n",
    "        self.gamma_neg = gamma_neg\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, target):\n",
    "        '''\n",
    "        \"input\" dimensions: - (batch_size,number_classes)\n",
    "        \"target\" dimensions: - (batch_size)\n",
    "        '''\n",
    "        num_classes = inputs.size()[-1]\n",
    "        log_preds = self.logsoftmax(inputs)\n",
    "        self.targets_classes = torch.zeros_like(inputs).scatter_(1, target.long().unsqueeze(1), 1)\n",
    "\n",
    "        # ASL weights\n",
    "        targets = self.targets_classes\n",
    "        anti_targets = 1 - targets\n",
    "        xs_pos = torch.exp(log_preds)\n",
    "        xs_neg = 1 - xs_pos\n",
    "        xs_pos = xs_pos * targets\n",
    "        xs_neg = xs_neg * anti_targets\n",
    "        asymmetric_w = torch.pow(1 - xs_pos - xs_neg,\n",
    "                                 self.gamma_pos * targets + self.gamma_neg * anti_targets)\n",
    "        log_preds = log_preds * asymmetric_w\n",
    "\n",
    "        if self.eps > 0:  # label smoothing\n",
    "            self.targets_classes = self.targets_classes.mul(1 - self.eps).add(self.eps / num_classes)\n",
    "\n",
    "        # loss calculation\n",
    "        loss = - self.targets_classes.mul(log_preds)\n",
    "\n",
    "        loss = loss.sum(dim=-1)\n",
    "        if self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a9b9ce-9530-4f39-9a1d-77e051042f16",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Ldam Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "226ee41d-eb88-4831-9f3b-8d85ecb8a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDAMLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, cls_num_list, max_m=0.5, weight=None, s=30):\n",
    "        super(LDAMLoss, self).__init__()\n",
    "        m_list = 1.0 / np.sqrt(np.sqrt(cls_num_list))\n",
    "        m_list = m_list * (max_m / np.max(m_list))\n",
    "        m_list = torch.cuda.FloatTensor(m_list)\n",
    "        self.m_list = m_list\n",
    "        assert s > 0\n",
    "        self.s = s\n",
    "        self.weight = weight\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        index = torch.zeros_like(x, dtype=torch.uint8)\n",
    "        index.scatter_(1, target.data.view(-1, 1), 1)\n",
    "        \n",
    "        index_float = index.type(torch.cuda.FloatTensor)\n",
    "        batch_m = torch.matmul(self.m_list[None, :], index_float.transpose(0,1))\n",
    "        batch_m = batch_m.view((-1, 1))\n",
    "        x_m = x - batch_m\n",
    "    \n",
    "        output = torch.where(index, x_m, x)\n",
    "        return F.cross_entropy(self.s*output, target, weight=self.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca68505-fba6-42e7-84c0-4162c4c40a4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Diverse Expert loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "002c2314-01bf-4d6e-92fa-e4b21bd8f203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DiverseExpertLoss(nn.Module):\n",
    "#     def __init__(self, cls_num_list=None, tau=5):\n",
    "#         super().__init__()\n",
    "#         self.base_loss = F.cross_entropy\n",
    "#         prior = np.array(cls_num_list) / np.sum(cls_num_list)\n",
    "#         self.prior = torch.tensor(prior).float().cuda()\n",
    "        \n",
    "#         self.tau = tau \n",
    "#         self.cls_num_list = cls_num_list\n",
    "\n",
    "#     def inverse_prior(self, prior): \n",
    "#         value, idx0 = torch.sort(prior)\n",
    "#         _, idx1 = torch.sort(idx0)\n",
    "#         idx2 = prior.shape[0]-1-idx1 # reverse the order\n",
    "#         inverse_prior = value.index_select(0,idx2)\n",
    "        \n",
    "#         return inverse_prior\n",
    "\n",
    "#     def forward(self, output_logits, target):\n",
    "#         loss = 0\n",
    "        \n",
    "#         # Obtain logits from each expert  \n",
    "#         expert1_logits = output_logits[\"base\"]\n",
    "#         # expert2_logits = output_logits[\"balance\"]\n",
    "#         expert3_logits = output_logits[\"inverse\"]\n",
    " \n",
    "#         # Softmax loss for expert 1 \n",
    "#         # loss += LDAMLoss(cls_num_list=self.cls_num_list, weight=prior)(expert1_logits, target)\n",
    "#         loss += self.base_loss(expert1_logits, target)\n",
    "        \n",
    "#         # Balanced Softmax loss for expert 2 \n",
    "#         # expert2_logits = expert2_logits + torch.log(self.prior + 1e-9) \n",
    "#         # loss += LDAMLoss(cls_num_list=self.cls_num_list)(expert2_logits, target)\n",
    "#         # loss += self.base_loss(expert2_logits, target)\n",
    "        \n",
    "#         # Inverse Softmax loss for expert 3\n",
    "#         inverse_prior = self.inverse_prior(self.prior)\n",
    "#         expert3_logits = expert3_logits + torch.log(self.prior + 1e-9) - self.tau * torch.log(inverse_prior+ 1e-9)\n",
    "#         # loss += LDAMLoss(cls_num_list=self.cls_num_list)(expert3_logits, target)\n",
    "#         loss += self.base_loss(expert3_logits, target)\n",
    "   \n",
    "#         return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa67c2d-e217-45bd-bcac-dccd8bb4462d",
   "metadata": {},
   "source": [
    "### Wing Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebc65f2e-16f1-4a1d-a677-e2d89dd02659",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WingLoss(nn.Module):\n",
    "    def __init__(self, omega=10, epsilon=2):\n",
    "        super(WingLoss, self).__init__()\n",
    "        self.omega = omega\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        y = target\n",
    "        y_hat = pred\n",
    "        delta_y = (y - y_hat).abs()\n",
    "        delta_y1 = delta_y[delta_y < self.omega]\n",
    "        delta_y2 = delta_y[delta_y >= self.omega]\n",
    "        loss1 = self.omega * torch.log(1 + delta_y1 / self.epsilon)\n",
    "        C = self.omega - self.omega * math.log(1 + self.omega / self.epsilon)\n",
    "        loss2 = delta_y2 - C\n",
    "        return (loss1.sum() + loss2.sum()) / (len(loss1) + len(loss2))\n",
    "    \n",
    "\n",
    "class AdaptiveWingLoss(nn.Module):\n",
    "    def __init__(self, omega=14, theta=0.5, epsilon=1, alpha=2.1):\n",
    "        super(AdaptiveWingLoss, self).__init__()\n",
    "        self.omega = omega\n",
    "        self.theta = theta\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        '''\n",
    "        :param pred: BxNxHxH\n",
    "        :param target: BxNxHxH\n",
    "        :return:\n",
    "        '''\n",
    "\n",
    "        y = target\n",
    "        y_hat = pred\n",
    "        delta_y = (y - y_hat).abs()\n",
    "        delta_y1 = delta_y[delta_y < self.theta]\n",
    "        delta_y2 = delta_y[delta_y >= self.theta]\n",
    "        y1 = y[delta_y < self.theta]\n",
    "        y2 = y[delta_y >= self.theta]\n",
    "        loss1 = self.omega * torch.log(1 + torch.pow(delta_y1 / self.omega, self.alpha - y1))\n",
    "        A = self.omega * (1 / (1 + torch.pow(self.theta / self.epsilon, self.alpha - y2))) * (self.alpha - y2) * (\n",
    "            torch.pow(self.theta / self.epsilon, self.alpha - y2 - 1)) * (1 / self.epsilon)\n",
    "        C = self.theta * A - self.omega * torch.log(1 + torch.pow(self.theta / self.epsilon, self.alpha - y2))\n",
    "        loss2 = A * delta_y2 - C\n",
    "        return (loss1.sum() + loss2.sum()) / (len(loss1) + len(loss2))\n",
    "\n",
    "\n",
    "class DiverseExpertLoss(nn.Module):\n",
    "    def __init__(self, cls_num_list=None, tau=5):\n",
    "        super().__init__()\n",
    "        self.base_loss = WingLoss().cuda()\n",
    "\n",
    "    def forward(self, output_logits, target):\n",
    "        loss = 0\n",
    "        \n",
    "        # Obtain logits from each expert  \n",
    "        expert1_logits = output_logits[\"image\"].squeeze(1)\n",
    "        expert2_logits = output_logits[\"meta\"].squeeze(1)\n",
    " \n",
    "        # wing loss for expert 1\n",
    "        loss += self.base_loss(expert1_logits, target)\n",
    "        \n",
    "        # wing loss for expert 2\n",
    "        loss += self.base_loss(expert2_logits, target)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81eda0c-1dee-408b-b969-a439e43abd12",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f19b526-97de-4fcf-8284-65aca00443dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdfa3d28-927c-49f5-8ece-756ca792524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAM(torch.optim.Optimizer):\n",
    "    def __init__(self, params, base_optimizer, rho=0.05, adaptive=False, **kwargs):\n",
    "        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n",
    "\n",
    "        defaults = dict(rho=rho, adaptive=adaptive, **kwargs)\n",
    "        super(SAM, self).__init__(params, defaults)\n",
    "\n",
    "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
    "        self.param_groups = self.base_optimizer.param_groups\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def first_step(self, zero_grad=False):\n",
    "        grad_norm = self._grad_norm()\n",
    "        for group in self.param_groups:\n",
    "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                self.state[p][\"old_p\"] = p.data.clone()\n",
    "                e_w = (torch.pow(p, 2) if group[\"adaptive\"] else 1.0) * p.grad * scale.to(p)\n",
    "                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def second_step(self, scaler=None, zero_grad=False):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                p.data = self.state[p][\"old_p\"]  # get back to \"w\" from \"w + e(w)\"\n",
    "\n",
    "        if scaler:\n",
    "            scaler.step(self.base_optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n",
    "        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass\n",
    "\n",
    "        self.first_step(zero_grad=True)\n",
    "        closure()\n",
    "        self.second_step()\n",
    "\n",
    "    def _grad_norm(self):\n",
    "        shared_device = self.param_groups[0][\"params\"][0].device  # put everything on the same device, in case of model parallelism\n",
    "        norm = torch.norm(\n",
    "                    torch.stack([\n",
    "                        ((torch.abs(p) if group[\"adaptive\"] else 1.0) * p.grad).norm(p=2).to(shared_device)\n",
    "                        for group in self.param_groups for p in group[\"params\"]\n",
    "                        if p.grad is not None\n",
    "                    ]),\n",
    "                    p=2\n",
    "               )\n",
    "        return norm\n",
    "    \n",
    "    def load_state_dict(self, state_dict):\n",
    "        super().load_state_dict(state_dict)\n",
    "        self.base_optimizer.param_groups = self.param_groups\n",
    "        \n",
    "\n",
    "def disable_running_stats(model):\n",
    "    def _disable(module):\n",
    "        if isinstance(module, nn.BatchNorm2d):\n",
    "            module.backup_momentum = module.momentum\n",
    "            module.momentum = 0\n",
    "\n",
    "    model.apply(_disable)\n",
    "\n",
    "def enable_running_stats(model):\n",
    "    def _enable(module):\n",
    "        if isinstance(module, nn.BatchNorm2d) and hasattr(module, \"backup_momentum\"):\n",
    "            module.momentum = module.backup_momentum\n",
    "\n",
    "    model.apply(_enable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3dc3bb-0978-43f5-bd60-dcac7b87c0aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CosineAnnealingWarmUpRestarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7d4a1c3-7204-474c-ba18-ee8f92c9ca39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CosineAnnealingWarmUpRestarts(torch.optim.lr_scheduler._LRScheduler):\n",
    "    def __init__(self, optimizer, T_0, T_mult=1, eta_max=0.1, T_up=0, gamma=1., last_epoch=-1):\n",
    "        if T_0 <= 0 or not isinstance(T_0, int):\n",
    "            raise ValueError(\"Expected positive integer T_0, but got {}\".format(T_0))\n",
    "        if T_mult < 1 or not isinstance(T_mult, int):\n",
    "            raise ValueError(\"Expected integer T_mult >= 1, but got {}\".format(T_mult))\n",
    "        if T_up < 0 or not isinstance(T_up, int):\n",
    "            raise ValueError(\"Expected positive integer T_up, but got {}\".format(T_up))\n",
    "        self.T_0 = T_0\n",
    "        self.T_mult = T_mult\n",
    "        self.base_eta_max = eta_max\n",
    "        self.eta_max = eta_max\n",
    "        self.T_up = T_up\n",
    "        self.T_i = T_0\n",
    "        self.gamma = gamma\n",
    "        self.cycle = 0\n",
    "        self.T_cur = last_epoch\n",
    "        super(CosineAnnealingWarmUpRestarts, self).__init__(optimizer, last_epoch)\n",
    "    \n",
    "    def get_lr(self):\n",
    "        if self.T_cur == -1:\n",
    "            return self.base_lrs\n",
    "        elif self.T_cur < self.T_up:\n",
    "            return [(self.eta_max - base_lr)*self.T_cur / self.T_up + base_lr for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr + (self.eta_max - base_lr) * (1 + math.cos(math.pi * (self.T_cur-self.T_up) / (self.T_i - self.T_up))) / 2\n",
    "                    for base_lr in self.base_lrs]\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "            self.T_cur = self.T_cur + 1\n",
    "            if self.T_cur >= self.T_i:\n",
    "                self.cycle += 1\n",
    "                self.T_cur = self.T_cur - self.T_i\n",
    "                self.T_i = (self.T_i - self.T_up) * self.T_mult + self.T_up\n",
    "        else:\n",
    "            if epoch >= self.T_0:\n",
    "                if self.T_mult == 1:\n",
    "                    self.T_cur = epoch % self.T_0\n",
    "                    self.cycle = epoch // self.T_0\n",
    "                else:\n",
    "                    n = int(math.log((epoch / self.T_0 * (self.T_mult - 1) + 1), self.T_mult))\n",
    "                    self.cycle = n\n",
    "                    self.T_cur = epoch - self.T_0 * (self.T_mult ** n - 1) / (self.T_mult - 1)\n",
    "                    self.T_i = self.T_0 * self.T_mult ** (n)\n",
    "            else:\n",
    "                self.T_i = self.T_0\n",
    "                self.T_cur = epoch\n",
    "                \n",
    "        self.eta_max = self.base_eta_max * (self.gamma**self.cycle)\n",
    "        self.last_epoch = math.floor(epoch)\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr\n",
    "        print(\"learning rate:\", lr)\n",
    "        neptune_run[\"train/learning_rate\"].log(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70be7929-f556-48f9-823f-a9e9cb333fb2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## AverageMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "283a62a8-a014-4cbd-969c-ba833a1ff210",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e2b4ee-78e5-4694-9739-55ec426841ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55cf4d1a-5d1a-47bb-8324-75ccc9a34d29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score\n",
    "    \n",
    "def calc_loss(z, j):\n",
    "    squared_error = torch.sum(z**2, (1, 2, 3)) / 2\n",
    "    jacob = torch.sum(j, (1, 2, 3))\n",
    "    return squared_error - jacob\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LR/2 * 0.01\n",
    "    if epoch >= int(EPOCHS*0.9):\n",
    "        lr = LR/2 * 0.000001\n",
    "    elif epoch >= int(EPOCHS*0.8):\n",
    "        lr = LR/2 * 0.0001\n",
    "    logger.info(\"learing rate:\", lr)\n",
    "    neptune_run[\"train/learning_rate\"].log(lr)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "        \n",
    "def cdb_adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    if epoch >= int(EPOCHS*0.9):\n",
    "        lr = LR/3 * 0.0001\n",
    "    elif epoch >= int(EPOCHS*0.8):\n",
    "        lr = LR/3 * 0.01\n",
    "    logger.info(\"learing rate:\", lr)\n",
    "    neptune_run[\"train/learning_rate\"].log(lr)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "        \n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mix_criterion(cr, pred, y_a, y_b, lam):\n",
    "    if cr == \"ib\":\n",
    "        return lam * criterion_ib(pred, y_a) + (1 - lam) * criterion_ib(pred, y_b)\n",
    "    elif cr == \"cr\":\n",
    "        return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "def get_transform():\n",
    "    transform = A.Compose([\n",
    "        A.Crop(x_min=408, y_min=0, x_max=2872, y_max=2464, p=1),\n",
    "        A.Resize(params[\"train_image_size\"][0], params[\"train_image_size\"][1], interpolation=cv2.INTER_AREA),\n",
    "        # A.Resize(params[\"train_image_size\"][0]+int(params[\"train_image_size\"][0]*0.2), params[\"train_image_size\"][1]+int(params[\"train_image_size\"][1]*0.2), interpolation=cv2.INTER_AREA),\n",
    "        # A.RandomCrop(params[\"train_image_size\"][0], params[\"train_image_size\"][1], p=1),\n",
    "        # A.RandomRotate90(p=0.5),\n",
    "        # A.HorizontalFlip(p=0.5),\n",
    "        # A.VerticalFlip(p=0.5),\n",
    "        # A.Affine(rotate=(-45, 45), translate_percent=(-0.1, 0.1), p=0.5),\n",
    "        # A.Cutout(num_holes=16, max_h_size=16, max_w_size=16, p=0.5),\n",
    "        # A.GaussNoise(p=0.5),\n",
    "        # A.RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "        A.Normalize(\n",
    "            # mean = [0.4849, 0.5310, 0.5719],\n",
    "            # std = [0.5511, 0.4834, 0.5929],\n",
    "            mean = [0.5, 0.5, 0.5],\n",
    "            std = [0.5, 0.5, 0.5],\n",
    "        ),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    return transform\n",
    "\n",
    "def train_transform(image):\n",
    "    transform = get_transform()\n",
    "    return transform(image=image)\n",
    "\n",
    "def test_transform(image):\n",
    "    transform = A.Compose([\n",
    "                    A.Crop(x_min=408, y_min=0, x_max=2872, y_max=2464, p=1),\n",
    "                    A.Resize(params[\"test_image_size\"][0], params[\"test_image_size\"][1], interpolation=cv2.INTER_AREA),\n",
    "                    A.Normalize(\n",
    "                        # mean = [0.4766, 0.5207, 0.6369],\n",
    "                        # std = [0.4530, 0.4062, 0.4842]\n",
    "                        mean = [0.5, 0.5, 0.5],\n",
    "                        std = [0.5, 0.5, 0.5],\n",
    "                        # mean = [0.4849, 0.5310, 0.5719],\n",
    "                        # std = [0.5511, 0.4834, 0.5929],\n",
    "                    ),\n",
    "                    ToTensorV2(),\n",
    "                ])\n",
    "    return transform(image=image)\n",
    "\n",
    "def cutmix(inputs, targets, beta=1.0, prob=1.0):\n",
    "    r = np.random.rand(1)[0]\n",
    "    if beta > 0 and r < prob:\n",
    "        # generate mixed sample\n",
    "        lam = np.random.beta(beta, beta)\n",
    "        rand_index = torch.randperm(inputs.size()[0]).cuda()\n",
    "        targets_a = targets\n",
    "        targets_b = targets[rand_index]\n",
    "        bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)\n",
    "        inputs[:, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "        # adjust lambda to exactly match pixel ratio\n",
    "        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (inputs.size()[-1] * inputs.size()[-2]))\n",
    "        return inputs, targets_a, targets_b, lam\n",
    "        \n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def get_nmae(outputs, targets):\n",
    "    mae = np.mean(np.abs(targets-outputs))\n",
    "    score = mae / np.mean(np.abs(targets))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb3a667-f7b6-4686-b0ee-98e1c598485f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c1e6d91-f141-484e-8e6a-baf78791ba4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_train_data(data_dir):\n",
    "    data_list = []\n",
    "    for case_name in os.listdir(data_dir):\n",
    "        current_path = os.path.join(data_dir, case_name)\n",
    "        label_df = pd.read_csv(current_path+'/label.csv')\n",
    "        for img_name, leaf_weight in zip(label_df[\"img_name\"], label_df[\"leaf_weight\"]):\n",
    "            data_list.append((os.path.join(current_path, \"image\", img_name), os.path.join(current_path, \"meta\", f\"{os.path.splitext(img_name)[0]}.csv\"), leaf_weight))\n",
    "    return data_list\n",
    "\n",
    "def get_test_data(data_dir):\n",
    "    # get image path\n",
    "    img_path_list = glob(os.path.join(data_dir, 'image', '*.jpg'))\n",
    "    img_path_list.extend(glob(os.path.join(data_dir, 'image', '*.png')))\n",
    "    img_path_list.sort(key=lambda x:int(x.split('/')[-1].split('.')[0]))\n",
    "    \n",
    "    # get meta path\n",
    "    meta_path_list = glob(os.path.join(data_dir, 'meta', '*.csv'))\n",
    "    meta_path_list.sort(key=lambda x:int(x.split('/')[-1].split('.')[0]))\n",
    "    return (img_path_list, meta_path_list)\n",
    "\n",
    "def get_scaler(data_list):\n",
    "    df = pd.DataFrame()\n",
    "    for data in data_list:\n",
    "        df = pd.concat([df, pd.read_csv(data[1]).dropna()])\n",
    "    df.drop([\"시간\"], axis=1, inplace=True)\n",
    "    scaler = getattr(preprocessing, params[\"scaler\"])()\n",
    "    scaler = scaler.fit(df)\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    imputer = imputer.fit(df)\n",
    "    return scaler, imputer\n",
    "\n",
    "\n",
    "train_data_list = get_train_data(TRAIN_PATH)\n",
    "scaler, imputer = get_scaler(train_data_list)\n",
    "\n",
    "# train_len = int(len(train_data_list)*0.8)\n",
    "# val_data_list = train_data_list[train_len:]\n",
    "# train_data_list = train_data_list[:train_len]\n",
    "\n",
    "# train_dataset = CustomDataset(train_data_list, mode=\"train\", transform=train_transform)\n",
    "# train_loader = DataLoader(\n",
    "#                     train_dataset,\n",
    "#                     batch_size=params[\"batch\"],\n",
    "#                     shuffle=True,\n",
    "#                     pin_memory=True,\n",
    "#                     num_workers=params[\"num_workers\"])\n",
    "\n",
    "# val_dataset = CustomDataset(val_data_list, mode=\"train\", transform=test_transform)\n",
    "# val_loader = DataLoader(\n",
    "#                     val_dataset,\n",
    "#                     batch_size=params[\"batch\"],\n",
    "#                     shuffle=True,\n",
    "#                     pin_memory=True,\n",
    "#                     num_workers=params[\"num_workers\"])\n",
    "\n",
    "\n",
    "\n",
    "# Get strong mean, std\n",
    "# strong_mean_std = OnlineMeanStd()\n",
    "# print(\"train:\", strong_mean_std(train_dataset, 1, \"strong\", \"train\"))\n",
    "# print(\"test:\", strong_mean_std(test_dataset, 1, \"strong\", \"test\"))\n",
    "neptune_run[\"transform\"] = str(get_transform())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa113c4f-634d-4462-88f6-1e8297d0bf3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb98893a-f16f-485a-bb89-b9f1e9f07871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def visualize(inputs, targets):\n",
    "#     # 이미지 정규화 해제하기\n",
    "#     inputs = inputs.moveaxis(0, -1)\n",
    "#     mean = np.array([0.4849, 0.5310, 0.5719])\n",
    "#     std = np.array([0.5511, 0.4834, 0.5929])\n",
    "#     inputs = inputs * std + mean\n",
    "#     inputs = np.clip(inputs, 0, 1)\n",
    "\n",
    "#     # 이미지 출력\n",
    "#     fig = plt.figure()\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.imshow(inputs, rasterized=True)\n",
    "#     plt.title(targets)\n",
    "#     plt.show()\n",
    "#     return fig\n",
    "    \n",
    "# for batch in train_loader:\n",
    "#     images, metas, labels = batch[0], batch[1], batch[2]\n",
    "#     for image, meta, label in zip(images, metas, labels):\n",
    "#     # for b in batch:\n",
    "#         # visualize(b, None)\n",
    "#         fig = visualize(image, label.item())\n",
    "#         neptune_run[\"preprocessed_image\"].log(fig)\n",
    "#     break\n",
    "\n",
    "# Cutmix\n",
    "# for batch in train_loader:\n",
    "#     inputs, targets = batch[0], batch[2]\n",
    "#     inputs, targets_a, targets_b, lam = cutmix(inputs, targets)\n",
    "#     for i, a, b in zip(inputs, targets_a, targets_b):\n",
    "#         visualize(i, f\"a:{a} / b:{b} / l: l\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa64565-5576-4709-a669-e06ed4a4220e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4d35476-0b51-4f52-bd93-721e9dc56af0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=params[\"lstm_input_size\"],\n",
    "            hidden_size=params[\"lstm_hidden_size\"],\n",
    "            num_layers=params[\"lstm_num_layers\"],\n",
    "            batch_first=params[\"lstm_batch_first\"],\n",
    "            bidirectional=params[\"lstm_bidirectional\"],\n",
    "            dropout=params[\"drop_out_rate\"],\n",
    "        )\n",
    "\n",
    "    def forward(self, x): \n",
    "        h0 = torch.zeros(params[\"lstm_num_layers\"]*2 if params[\"lstm_bidirectional\"] else params[\"lstm_num_layers\"], x.size(0), params[\"lstm_hidden_size\"]).to(DEVICE)\n",
    "        # c0 = torch.zeros(params[\"lstm_num_layers\"]*2 if params[\"lstm_bidirectional\"] else params[\"lstm_num_layers\"], x.size(0), params[\"lstm_hidden_size\"]).to(DEVICE)\n",
    "        out, _ = self.rnn(x, h0)#(h0, c0))\n",
    "        return out[:, -1]\n",
    "\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self, mode=\"train\"):\n",
    "        super(Network, self).__init__()\n",
    "        self.mode = mode\n",
    "        if self.mode == \"train\":\n",
    "            self.drop_out_rate = params[\"drop_out_rate\"]\n",
    "            self.drop_path_rate = params[\"drop_path_rate\"]\n",
    "        elif self.mode == \"test\":\n",
    "            self.drop_out_rate = 0\n",
    "            self.drop_path_rate = 0\n",
    "        \n",
    "        if \"tresnet\" in params[\"model_name\"]:\n",
    "            self.backbone = timm.create_model(params[\"model_name\"],\n",
    "                                              pretrained=True,\n",
    "                                              num_classes=0,\n",
    "                                              drop_rate=self.drop_out_rate,)\n",
    "        else:\n",
    "            self.backbone = timm.create_model(params[\"model_name\"],\n",
    "                                              pretrained=True,\n",
    "                                              num_classes=0,\n",
    "                                              drop_rate=self.drop_out_rate,\n",
    "                                              drop_path_rate=self.drop_path_rate)\n",
    "        if \"swin\" in params[\"model_name\"] or \"beit\" in params[\"model_name\"]:\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Linear(self.backbone.norm.normalized_shape[0]+(params[\"lstm_hidden_size\"]*2 if params[\"lstm_bidirectional\"] else params[\"lstm_hidden_size\"]), params[\"num_class\"]),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        elif \"efficient\" in params[\"model_name\"]:\n",
    "            self.classifier = nn.Sequential(\n",
    "                    nn.Linear(self.backbone.conv_head.out_channels+1440, params[\"num_class\"]),\n",
    "                    nn.ReLU(inplace=True)\n",
    "                )\n",
    "        elif \"tresnet\" in params[\"model_name\"]:\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Linear(2432 + 1440, params[\"num_class\"]),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        # self.rnn = RNN()\n",
    "        \n",
    "    def forward(self, x, meta):\n",
    "        if self.mode == \"train\":\n",
    "            # meta = self.rnn(meta)\n",
    "            meta = torch.mean(meta, dim=2)\n",
    "            x = self.backbone(x) # torch.Size([32, 1280]) torch.Size([32, 1440])\n",
    "            x = torch.cat([x, meta], 1) # 2720\n",
    "            x = self.classifier(x)\n",
    "            return x\n",
    "        \n",
    "        elif self.mode == \"test\":\n",
    "            # meta = self.rnn(meta)\n",
    "            meta = torch.mean(meta, dim=2)\n",
    "            x = self.backbone(x)\n",
    "            x = torch.cat([x, meta], 1)\n",
    "            x = self.classifier(x)\n",
    "            return x\n",
    "\n",
    "\n",
    "# class NormedLinear(nn.Module):\n",
    "\n",
    "#     def __init__(self, in_features, out_features):\n",
    "#         super(NormedLinear, self).__init__()\n",
    "#         self.weight = Parameter(torch.Tensor(in_features, out_features))\n",
    "#         self.weight.data.uniform_(-1, 1).renorm_(2, 1, 1e-5).mul_(1e5)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         out = F.normalize(x, dim=1).mm(F.normalize(self.weight, dim=0))\n",
    "#         return out\n",
    "    \n",
    "\n",
    "class NormedLinear(nn.Linear):\n",
    "    \"\"\"Normalized Linear Layer.\n",
    "    Args:\n",
    "        tempeature (float, optional): Tempeature term. Default to 20.\n",
    "        power (int, optional): Power term. Default to 1.0.\n",
    "        eps (float, optional): The minimal value of divisor to\n",
    "             keep numerical stability. Default to 1e-6.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, tempearture=20, power=1.0, eps=1e-6, **kwargs):\n",
    "        super(NormedLinear, self).__init__(*args, **kwargs)\n",
    "        self.tempearture = tempearture\n",
    "        self.power = power\n",
    "        self.eps = eps\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        nn.init.normal_(self.weight, mean=0, std=0.01)\n",
    "        if self.bias is not None:\n",
    "            nn.init.constant_(self.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        weight_ = self.weight / (\n",
    "            self.weight.norm(dim=1, keepdim=True).pow(self.power) + self.eps)\n",
    "        x_ = x / (x.norm(dim=1, keepdim=True).pow(self.power) + self.eps)\n",
    "        x_ = x_ * self.tempearture\n",
    "\n",
    "        return F.linear(x_, weight_, self.bias)\n",
    "    \n",
    "    \n",
    "# model = Network()\n",
    "# model\n",
    "# # logger.info(model(torch.randn(1, 3, 224, 224)))\n",
    "# logger.info(model)\n",
    "# model.to(DEVICE)\n",
    "# logger.info(f\"model {MODEL_NAME} create!\")\n",
    "\n",
    "# model\n",
    "# from pprint import pprint\n",
    "# model_names = timm.list_models(\"*hrnet*\", pretrained=False)\n",
    "# pprint(model_names)\n",
    "# z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecfe24a-ac75-4037-b3ea-27c4a873c34a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dyhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fad7005d-fc0a-44df-aa8f-f8baae4c22d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # # from pprint import pprint\n",
    "# # # model_names = timm.list_models(\"*swin*\", pretrained=True)\n",
    "# # # pprint(model_names)\n",
    "# from collections import OrderedDict\n",
    "\n",
    "# class Network(nn.Module):\n",
    "#     def __init__(self, mode=\"train\"):\n",
    "#         super(Network, self).__init__()\n",
    "#         out_featrues = 256\n",
    "#         self.mode = mode\n",
    "#         # self.backbone = timm.create_model(MODEL_NAME, pretrained=True, num_classes=NUM_CLASS, drop_path_rate=DROP_PATH_RATIO)#num_classes=0, global_pool=\"\")#, drop_path_rate=0.2)\n",
    "#         self.backbone = timm.create_model(MODEL_NAME, pretrained=True, features_only=True, drop_path_rate=DROP_PATH_RATIO)\n",
    "#         self.fpn = FeaturePyramidNetwork([48, 64, 160, 256], out_featrues)\n",
    "#         self.concat_fpn = concat_feature_maps()\n",
    "#         # self.scale_layer = Scale_Aware_Layer\n",
    "#         # self.spatial_layer = Spatial_Aware_Layer\n",
    "#         # self.task_layer = Task_Aware_Layer\n",
    "#         # L: 4 S: 441 C: 256\n",
    "#         self.dyhead = DyHead(num_blocks=6, L=4, S=784, C=256)\n",
    "#         self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "#         self.classifier = nn.Linear(256, NUM_CLASS)\n",
    "#         # self.ml_decoder = MLDecoder(NUM_CLASS, initial_num_features=1280)\n",
    "#         # for _, param in self.backbone.named_parameters():\n",
    "#         #     param.requires_grad = False\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.backbone(x)[1:]\n",
    "\n",
    "#         x_dic = OrderedDict()\n",
    "#         for i in range(len(x)):\n",
    "#             x_dic[f\"feat{i}\"] = x[i]\n",
    "\n",
    "#         x = self.fpn(x_dic)\n",
    "#         x = self.concat_fpn(x)\n",
    "#         x = self.dyhead(x)\n",
    "        \n",
    "#         F_tensor = x.permute(0, 3, 1, 2)\n",
    "#         kernel_size = F_tensor.shape[2:] # Getting HxW of F\n",
    "#         gap_output = F.avg_pool2d(F_tensor, kernel_size)\n",
    "\n",
    "#         # Flattening gap_output from (batch_size, C, 1, 1) to (batch_size, C)\n",
    "#         gap_output = gap_output.flatten(start_dim=1)\n",
    "        \n",
    "#         # x = x.transpose(dim0=1, dim1=-1)\n",
    "#         # x = self.avg_pool(x)\n",
    "#         # x = x.flatten(1)\n",
    "#         x = self.classifier(gap_output)\n",
    "#         return x\n",
    "#         # feats = []\n",
    "#         # for k, v in x.items():\n",
    "#         #     v = self.avg_pool(v)\n",
    "#         #     feats.append(v.flatten(1))\n",
    "#         # feats = torch.cat(feats, 1)\n",
    "        \n",
    "#         # x = self.classifier(x)\n",
    "#         # feats = self.backbone(x)\n",
    "#         # x = self.classifier(feats)\n",
    "#         # x = self.ml_decoder(x)\n",
    "#         # return x\n",
    "#         # if self.mode == \"train\":\n",
    "#         #     return x, torch.sum(torch.abs(feats), 1).reshape(-1, 1)\n",
    "#         # else:\n",
    "\n",
    "        \n",
    "# class concat_feature_maps(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(concat_feature_maps, self).__init__()\n",
    "\n",
    "#     def forward(self, fpn_output):\n",
    "#         # Calculating median height to upsample or desample each fpn levels\n",
    "#         heights = []\n",
    "#         level_tensors = []\n",
    "#         for key, values in fpn_output.items():\n",
    "#             heights.append(values.shape[2])\n",
    "#             level_tensors.append(values)\n",
    "#         median_height = int(np.median(heights))\n",
    "\n",
    "#         # Upsample and Desampling tensors to median height and width\n",
    "#         for i in range(len(level_tensors)):\n",
    "#             level = level_tensors[i]\n",
    "#             # If level height is greater than median, then downsample with interpolate\n",
    "#             if level.shape[2] > median_height:\n",
    "#                 level = F.interpolate(input=level, size=(median_height, median_height),mode='nearest')\n",
    "#             # If level height is less than median, then upsample\n",
    "#             else:\n",
    "#                 level = F.interpolate(input=level, size=(median_height, median_height), mode='nearest')\n",
    "#             level_tensors[i] = level\n",
    "        \n",
    "#         # Concating all levels with dimensions (batch_size, levels, C, H, W)\n",
    "#         concat_levels = torch.stack(level_tensors, dim=1)\n",
    "\n",
    "#         # Reshaping tensor from (batch_size, levels, C, H, W) to (batch_size, levels, HxW=S, C)\n",
    "#         concat_levels = concat_levels.flatten(start_dim=3).transpose(dim0=2, dim1=3)\n",
    "#         return concat_levels\n",
    "\n",
    "\n",
    "# class Scale_Aware_Layer(nn.Module):\n",
    "#     # Constructor\n",
    "#     def __init__(self, s_size):\n",
    "#         super(Scale_Aware_Layer, self).__init__()\n",
    "\n",
    "#         # Average Pooling\n",
    "#         self.avg_layer = nn.AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "#         #1x1 Conv layer\n",
    "#         self.conv = nn.Conv2d(in_channels=s_size, out_channels=1, kernel_size=1)\n",
    "\n",
    "#         # Hard Sigmoid\n",
    "#         self.hard_sigmoid = nn.Hardsigmoid()\n",
    "\n",
    "#         # ReLU function\n",
    "#         self.relu = nn.ReLU()\n",
    "\n",
    "#     def forward(self, F):\n",
    "\n",
    "#         # Transposing input from (batch_size, L, S, C) to (batch_size, S, L, C) so we can use convolutional layer over the level dimension L\n",
    "#         x = F.transpose(dim0=2, dim1=1)\n",
    "\n",
    "#         # Passing tensor through avg pool layer\n",
    "#         x = self.avg_layer(x)\n",
    "\n",
    "#         # Passing tensor through Conv layer\n",
    "#         x = self.conv(x)\n",
    "        \n",
    "#         # Reshaping Tensor from (batch_size, 1, L, C) to (batch_size, L, 1, C) to then be multiplied to F\n",
    "#         x = x.transpose(dim0=1, dim1=2)\n",
    "\n",
    "#         # Passing conv output to relu\n",
    "#         x = self.relu(x)\n",
    "\n",
    "#         # Passing tensor to hard sigmoid function\n",
    "#         pi_L = self.hard_sigmoid(x)\n",
    "\n",
    "#         # pi_L: (batch_size, L, 1, C)\n",
    "#         # F: (batch_size, L, S, C)\n",
    "#         return pi_L * F\n",
    "\n",
    "    \n",
    "# class Spatial_Aware_Layer(nn.Module):\n",
    "#     # Constructor\n",
    "#     def __init__(self, L_size, kernel_height=3, kernel_width=3, padding=1, stride=1, dilation=1, groups=1):\n",
    "#         super(Spatial_Aware_Layer, self).__init__()\n",
    "\n",
    "#         self.in_channels = L_size\n",
    "#         self.out_channels = L_size\n",
    "\n",
    "#         self.kernel_size = (kernel_height, kernel_width)\n",
    "#         self.padding = padding\n",
    "#         self.stride = stride\n",
    "#         self.dilation = dilation\n",
    "#         self.K = kernel_height * kernel_width\n",
    "#         self.groups = groups\n",
    "\n",
    "#         # 3x3 Convolution with 3K out_channel output as described in Deform Conv2 paper\n",
    "#         self.offset_and_mask_conv = nn.Conv2d(in_channels=self.in_channels,\n",
    "#                                               out_channels=3*self.K, #3K depth\n",
    "#                                               kernel_size=self.kernel_size,\n",
    "#                                               stride=self.stride,\n",
    "#                                               padding=self.padding,\n",
    "#                                               dilation=dilation)\n",
    "        \n",
    "#         self.deform_conv = DeformConv2d(in_channels=self.in_channels,\n",
    "#                                         out_channels=self.out_channels,\n",
    "#                                         kernel_size=self.kernel_size,\n",
    "#                                         stride=self.stride,\n",
    "#                                         padding=self.padding,\n",
    "#                                         dilation=self.dilation,\n",
    "#                                         groups=self.groups)\n",
    "#     def forward(self, F):\n",
    "#         # Generating offesets and masks (or modulators) for convolution operation\n",
    "#         offsets_and_masks = self.offset_and_mask_conv(F)\n",
    "\n",
    "#         # Separating offsets and masks as described in Deform Conv v2 paper\n",
    "#         offset = offsets_and_masks[:, :2*self.K, :, :] # First 2K channels \n",
    "#         mask = torch.sigmoid(offsets_and_masks[:, 2*self.K:, : , :]) # Last 1K channels and passing it through sigmoid\n",
    "\n",
    "#         # Passing offsets, masks, and F into deform conv layer\n",
    "#         spacial_output = self.deform_conv(F, offset, mask)\n",
    "#         return spacial_output\n",
    "\n",
    "    \n",
    "# # DyReLUA technique from Dynamic ReLU paper\n",
    "# class DyReLUA(nn.Module):\n",
    "#     def __init__(self, channels, reduction=8, k=2, lambdas=None, init_values=None):\n",
    "#         super(DyReLUA, self).__init__()\n",
    "\n",
    "#         self.fc1 = nn.Linear(channels, channels // reduction)\n",
    "#         self.fc2 = nn.Linear(channels//reduction, 2*k)\n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "#         # Defining lambdas in form of [La1, La2, Lb1, Lb2]\n",
    "#         if lambdas is not None:\n",
    "#             self.lambdas = lambdas\n",
    "#         else:\n",
    "#             # Default lambdas from DyReLU paper\n",
    "#             self.lambdas = torch.cuda.HalfTensor([1.0, 1.0, 0.5, 0.5])\n",
    "\n",
    "#         # Defining Initializing values in form of [alpha1, alpha2, Beta1, Beta2]\n",
    "#         if lambdas is not None:\n",
    "#             self.init_values = init_values\n",
    "#         else:\n",
    "#             # Default initializing values of DyReLU paper\n",
    "#             self.init_values = torch.cuda.HalfTensor([1.0, 0.0, 0.0, 0.0])\n",
    "\n",
    "#     def forward(self, F_tensor):\n",
    "\n",
    "#         # Global Averaging F\n",
    "#         kernel_size = F_tensor.shape[2:] # Getting HxW of F\n",
    "#         gap_output = F.avg_pool2d(F_tensor, kernel_size)\n",
    "\n",
    "#         # Flattening gap_output from (batch_size, C, 1, 1) to (batch_size, C)\n",
    "#         gap_output = gap_output.flatten(start_dim=1)\n",
    "\n",
    "#         # Passing Global Average output through Fully-Connected Layers\n",
    "#         x = self.relu(self.fc1(gap_output))\n",
    "#         x = self.fc2(x)\n",
    "        \n",
    "#         # Normalization between (-1, 1)\n",
    "#         residuals = 2 * self.sigmoid(x) - 1\n",
    "\n",
    "#         # Getting values of theta, and separating alphas and betas\n",
    "#         theta = self.init_values + self.lambdas * residuals # Contains[alpha1(x), alpha2(x), Beta1(x), Beta2(x)]\n",
    "#         alphas = theta[0, :2]\n",
    "#         betas = theta[0, 2:]\n",
    "\n",
    "#         # Performing maximum on both piecewise functions\n",
    "#         output = torch.maximum((alphas[0] * F_tensor + betas[0]), (alphas[1] * F_tensor + betas[1]))\n",
    "\n",
    "#         return output\n",
    "\n",
    "    \n",
    "# class Task_Aware_Layer(nn.Module):\n",
    "#     # Defining constructor\n",
    "#     def __init__(self, num_channels):\n",
    "#         super(Task_Aware_Layer, self).__init__()\n",
    "\n",
    "#         # DyReLUA relu\n",
    "#         self.dynamic_relu = DyReLUA(num_channels)\n",
    "    \n",
    "#     def forward(self, F_tensor):\n",
    "#         # Permutating F from (batch_size, L, S, C) to (batch_size, C, L, S) so we can reduce the dimensions over LxS\n",
    "#         F_tensor = F_tensor.permute(0, 3, 1, 2)\n",
    "#         output = self.dynamic_relu(F_tensor)\n",
    "        \n",
    "#         # Reversing the permutation\n",
    "#         output = output.permute(0, 2, 3, 1)\n",
    "\n",
    "#         return output\n",
    "\n",
    "\n",
    "# class DyHead_Block(nn.Module):\n",
    "#     def __init__(self, L, S, C):\n",
    "#         super(DyHead_Block, self).__init__()\n",
    "#         # Saving all dimension sizes of F\n",
    "#         self.L_size = L\n",
    "#         self.S_size = S\n",
    "#         self.C_size = C\n",
    "\n",
    "#         # Inititalizing all attention layers\n",
    "#         self.scale_attention = Scale_Aware_Layer(s_size=self.S_size)\n",
    "#         self.spatial_attention = Spatial_Aware_Layer(L_size=self.L_size)\n",
    "#         self.task_attention = Task_Aware_Layer(num_channels=self.C_size)\n",
    "\n",
    "#     def forward(self, F_tensor):\n",
    "#         scale_output = self.scale_attention(F_tensor)\n",
    "#         spacial_output = self.spatial_attention(scale_output)\n",
    "#         task_output = self.task_attention(spacial_output)\n",
    "\n",
    "#         return task_output\n",
    "\n",
    "# def DyHead(num_blocks, L, S, C):\n",
    "#     blocks = [('Block_{}'.format(i+1),DyHead_Block(L, S, C)) for i in range(num_blocks)]\n",
    "\n",
    "#     return nn.Sequential(OrderedDict(blocks))\n",
    "\n",
    "\n",
    "# model = Network()\n",
    "# model.to(DEVICE)\n",
    "# logger.info(f\"model {MODEL_NAME} create!\")\n",
    "# # for i, (k, param) in enumerate(model.named_parameters()):\n",
    "# #     if i < 644:\n",
    "# #         param.requires_grad = False\n",
    "# #     print(i, k, param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796231d7-4f63-416f-b0db-c7a3287cc28f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ML-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a25a0b2-5771-4ed2-81fe-23afefa73ef1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_ml_decoder_head(model, num_classes=-1, num_of_groups=-1, decoder_embedding=768, zsl=0):\n",
    "    if num_classes == -1:\n",
    "        num_classes = model.num_classes\n",
    "    num_features = model.num_features\n",
    "    if hasattr(model, 'global_pool') and hasattr(model, 'fc'):  # resnet50\n",
    "        model.global_pool = nn.Identity()\n",
    "        del model.fc\n",
    "        model.fc = MLDecoder(num_classes=num_classes, initial_num_features=num_features, num_of_groups=num_of_groups,\n",
    "                             decoder_embedding=decoder_embedding, zsl=zsl)\n",
    "    elif hasattr(model, 'head'):  # tresnet\n",
    "        if hasattr(model, 'global_pool'):\n",
    "            model.global_pool = nn.Identity()\n",
    "        del model.head\n",
    "        model.head = MLDecoder(num_classes=num_classes, initial_num_features=num_features, num_of_groups=num_of_groups,\n",
    "                               decoder_embedding=decoder_embedding, zsl=zsl)\n",
    "    else:\n",
    "        print(\"model is not suited for ml-decoder\")\n",
    "        exit(-1)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "class TransformerDecoderLayerOptimal(nn.Module):\n",
    "    def __init__(self, d_model, nhead=8, dim_feedforward=2048, dropout=0.1, activation=\"relu\",\n",
    "                 layer_norm_eps=1e-5) -> None:\n",
    "        super(TransformerDecoderLayerOptimal, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(d_model, eps=layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "\n",
    "        self.multihead_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "\n",
    "        # Implementation of Feedforward model\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "\n",
    "        self.norm2 = nn.LayerNorm(d_model, eps=layer_norm_eps)\n",
    "        self.norm3 = nn.LayerNorm(d_model, eps=layer_norm_eps)\n",
    "\n",
    "        self.activation = _get_activation_fn(activation)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        if 'activation' not in state:\n",
    "            state['activation'] = torch.nn.functional.relu\n",
    "        super(TransformerDecoderLayerOptimal, self).__setstate__(state)\n",
    "\n",
    "    def forward(self, tgt, memory, tgt_mask = None,\n",
    "                memory_mask = None,\n",
    "                tgt_key_padding_mask = None,\n",
    "                memory_key_padding_mask = None):\n",
    "        tgt = tgt + self.dropout1(tgt)\n",
    "        tgt = self.norm1(tgt)\n",
    "        tgt2 = self.multihead_attn(tgt, memory, memory)[0]\n",
    "        tgt = tgt + self.dropout2(tgt2)\n",
    "        tgt = self.norm2(tgt)\n",
    "        tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt))))\n",
    "        tgt = tgt + self.dropout3(tgt2)\n",
    "        tgt = self.norm3(tgt)\n",
    "        return tgt\n",
    "\n",
    "class GroupFC(object):\n",
    "    def __init__(self, embed_len_decoder: int):\n",
    "        self.embed_len_decoder = embed_len_decoder\n",
    "\n",
    "    def __call__(self, h, duplicate_pooling, out_extrap):\n",
    "        for i in range(h.shape[1]):\n",
    "            h_i = h[:, i, :]\n",
    "            if len(duplicate_pooling.shape)==3:\n",
    "                w_i = duplicate_pooling[i, :, :]\n",
    "            else:\n",
    "                w_i = duplicate_pooling\n",
    "            out_extrap[:, i, :] = torch.matmul(h_i, w_i)\n",
    "\n",
    "\n",
    "class MLDecoder(nn.Module):\n",
    "    def __init__(self, num_classes, num_of_groups=-1, decoder_embedding=768,\n",
    "                 initial_num_features=2048, zsl=0):\n",
    "        super(MLDecoder, self).__init__()\n",
    "        embed_len_decoder = 100 if num_of_groups < 0 else num_of_groups\n",
    "        if embed_len_decoder > num_classes:\n",
    "            embed_len_decoder = num_classes\n",
    "\n",
    "        # switching to 768 initial embeddings\n",
    "        decoder_embedding = 768 if decoder_embedding < 0 else decoder_embedding\n",
    "        embed_standart = nn.Linear(initial_num_features, decoder_embedding)\n",
    "\n",
    "        # non-learnable queries\n",
    "        if not zsl:\n",
    "            query_embed = nn.Embedding(embed_len_decoder, decoder_embedding)\n",
    "            query_embed.requires_grad_(False)\n",
    "        else:\n",
    "            query_embed = None\n",
    "\n",
    "        # decoder\n",
    "        decoder_dropout = 0.1\n",
    "        num_layers_decoder = 1\n",
    "        dim_feedforward = 2048\n",
    "        layer_decode = TransformerDecoderLayerOptimal(d_model=decoder_embedding,\n",
    "                                                      dim_feedforward=dim_feedforward, dropout=decoder_dropout)\n",
    "        self.decoder = nn.TransformerDecoder(layer_decode, num_layers=num_layers_decoder)\n",
    "        self.decoder.embed_standart = embed_standart\n",
    "        self.decoder.query_embed = query_embed\n",
    "        self.zsl = zsl\n",
    "\n",
    "        if self.zsl:\n",
    "            if decoder_embedding != 300:\n",
    "                self.wordvec_proj = nn.Linear(300, decoder_embedding)\n",
    "            else:\n",
    "                self.wordvec_proj = nn.Identity()\n",
    "            self.decoder.duplicate_pooling = torch.nn.Parameter(torch.Tensor(decoder_embedding, 1))\n",
    "            self.decoder.duplicate_pooling_bias = torch.nn.Parameter(torch.Tensor(1))\n",
    "            self.decoder.duplicate_factor = 1\n",
    "        else:\n",
    "            # group fully-connected\n",
    "            self.decoder.num_classes = num_classes\n",
    "            self.decoder.duplicate_factor = int(num_classes / embed_len_decoder + 0.999)\n",
    "            self.decoder.duplicate_pooling = torch.nn.Parameter(\n",
    "                torch.Tensor(embed_len_decoder, decoder_embedding, self.decoder.duplicate_factor))\n",
    "            self.decoder.duplicate_pooling_bias = torch.nn.Parameter(torch.Tensor(num_classes))\n",
    "        torch.nn.init.xavier_normal_(self.decoder.duplicate_pooling)\n",
    "        torch.nn.init.constant_(self.decoder.duplicate_pooling_bias, 0)\n",
    "        self.decoder.group_fc = GroupFC(embed_len_decoder)\n",
    "        self.train_wordvecs = None\n",
    "        self.test_wordvecs = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 4:  # [bs,2048, 7,7]\n",
    "            embedding_spatial = x.flatten(2).transpose(1, 2)\n",
    "        else:  # [bs, 197,468]\n",
    "            embedding_spatial = x\n",
    "        embedding_spatial_786 = self.decoder.embed_standart(embedding_spatial)\n",
    "        embedding_spatial_786 = torch.nn.functional.relu(embedding_spatial_786, inplace=True)\n",
    "\n",
    "        bs = embedding_spatial_786.shape[0]\n",
    "        if self.zsl:\n",
    "            query_embed = torch.nn.functional.relu(self.wordvec_proj(self.decoder.query_embed))\n",
    "        else:\n",
    "            query_embed = self.decoder.query_embed.weight\n",
    "        # tgt = query_embed.unsqueeze(1).repeat(1, bs, 1)\n",
    "        tgt = query_embed.unsqueeze(1).expand(-1, bs, -1)  # no allocation of memory with expand\n",
    "        h = self.decoder(tgt, embedding_spatial_786.transpose(0, 1))  # [embed_len_decoder, batch, 768]\n",
    "        h = h.transpose(0, 1)\n",
    "\n",
    "        out_extrap = torch.zeros(h.shape[0], h.shape[1], self.decoder.duplicate_factor, device=h.device, dtype=h.dtype)\n",
    "        self.decoder.group_fc(h, self.decoder.duplicate_pooling, out_extrap)\n",
    "        if not self.zsl:\n",
    "            h_out = out_extrap.flatten(1)[:, :self.decoder.num_classes]\n",
    "        else:\n",
    "            h_out = out_extrap.flatten(1)\n",
    "        h_out += self.decoder.duplicate_pooling_bias\n",
    "        logits = h_out\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407f487c-71b8-484a-9fd7-ba7d0143506f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Optimizer & Criterion & Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94e1ed0d-cc51-4872-a67e-6bbf951f10ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i, (k, param) in enumerate(model.named_parameters()):\n",
    "#     if i < 363:\n",
    "#         param.requires_grad = False\n",
    "#     print(i, k, param.requires_grad)\n",
    "def set_optimizer():\n",
    "    if \"sam\" in params[\"optimizer\"]:\n",
    "        if \"adamw\" in params[\"optimizer\"]:\n",
    "            base_optimizer = torch.optim.AdamW\n",
    "        elif \"sgd\" in params[\"optimizer\"]:\n",
    "            base_optimizer = torch.optim.SGD\n",
    "            optimizer = SAM(model.parameters(), base_optimizer, lr=params[\"learning_rate\"], rho=2.0, adaptive=True, momentum=0.9, weight_decay=params[\"weight_decay\"])\n",
    "        elif \"lamb\" in params[\"optimizer\"]:\n",
    "            base_optimizer = optim.Lamb\n",
    "            optimizer = SAM(model.parameters(), base_optimizer, lr=params[\"learning_rate\"], rho=2.0, adaptive=True, betas=(0.9, 0.999), eps=1e-6, weight_decay=params[\"weight_decay\"])\n",
    "        if \"cosineannealinglr\" in params[\"scheduler\"]:\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer.base_optimizer, T_max=params[\"epochs\"], verbose=True)\n",
    "        elif \"cosineannealingwarmuprestarts\" in params[\"scheduler\"]:\n",
    "            scheduler = CosineAnnealingWarmUpRestarts(optimizer.base_optimizer, T_0=25, T_mult=1, eta_max=params[\"learning_rate\"],  T_up=5, gamma=0.1)\n",
    "    else:\n",
    "        if \"adamw\" in params[\"optimizer\"]:\n",
    "            optimizer = torch.optim.AdamW(model.parameters(), lr=1e-30, weight_decay=params[\"weight_decay\"])\n",
    "        elif \"sgd\" in params[\"optimizer\"]:\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=params[\"learning_rate\"], weight_decay=params[\"weight_decay\"], momentum=0.9)\n",
    "        elif \"lamb\" in params[\"optimizer\"]:\n",
    "            optimizer = optim.Lamb(model.parameters(), lr=params[\"learning_rate\"], betas=(0.9, 0.999), eps=1e-6, weight_decay=params[\"weight_decay\"])\n",
    "        if \"cosineannealinglr\" in params[\"scheduler\"]:\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=params[\"epochs\"], verbose=True)\n",
    "        elif \"cosineannealingwarmuprestarts\" in params[\"scheduler\"]:\n",
    "            scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=25, T_mult=1, eta_max=params[\"learning_rate\"],  T_up=0, gamma=0.1)\n",
    "\n",
    "    if \"ib\" in params[\"criterion\"]:\n",
    "        per_cls_weights = 1.0 / np.array(SAMPLES_PER_CLS)\n",
    "        per_cls_weights = per_cls_weights / np.sum(per_cls_weights) * len(SAMPLES_PER_CLS)\n",
    "        per_cls_weights = torch.FloatTensor(per_cls_weights).cuda()\n",
    "        criterion = nn.CrossEntropyLoss().cuda()\n",
    "        criterion_ib = IB_FocalLoss(weight=per_cls_weights, alpha=1000, gamma=1).cuda()\n",
    "        # criterion_ib = IBLoss(weight=per_cls_weights, alpha=1000).cuda()\n",
    "    elif \"ce\" in params[\"criterion\"]:\n",
    "        criterion = nn.CrossEntropyLoss().cuda()\n",
    "    elif \"sc\" in params[\"criterion\"]:\n",
    "        criterion = SmoothCrossentropy().cuda()\n",
    "    elif \"de\" in params[\"criterion\"]:\n",
    "        criterion = DiverseExpertLoss(SAMPLES_PER_CLS).cuda()\n",
    "    elif \"bs\" in params[\"criterion\"]:\n",
    "        criterion = BalancedSoftmax().cuda()\n",
    "    elif \"l1\" in params[\"criterion\"]:\n",
    "        criterion = nn.L1Loss().cuda()\n",
    "    elif \"huber\" in params[\"criterion\"]:\n",
    "        criterion = nn.HuberLoss(delta=params[\"huber_delta\"]).cuda()\n",
    "    elif \"cosine_similarity\" in params[\"criterion\"]:\n",
    "        criterion = nn.CosineSimilarity().cuda()\n",
    "    elif \"wing\" in params[\"criterion\"]:\n",
    "        criterion = WingLoss().cuda()\n",
    "    elif \"adaptivewing\" in params[\"criterion\"]:\n",
    "        criterion = AdaptiveWingLoss().cuda()\n",
    "    elif \"expert\" in params[\"criterion\"]:\n",
    "        criterion = DiverseExpertLoss().cuda()\n",
    "    # elif \"robust\" in params[\"criterion\"]:\n",
    "    #     criterion = robust_loss_pytorch.adaptive.AdaptiveLossFunction(num_dims=1, float_dtype=np.float32, device=0)\n",
    "    #     robust_params = list(model.parameters()) + list(criterion.parameters())\n",
    "    #     base_optimizer = optim.Lamb\n",
    "    #     optimizer = SAM(robust_params, base_optimizer, lr=params[\"learning_rate\"], rho=2.0, adaptive=True, betas=(0.9, 0.999), eps=1e-6, weight_decay=params[\"weight_decay\"])\n",
    "    #     scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer.base_optimizer, T_max=params[\"epochs\"], verbose=True)\n",
    "\n",
    "    grad_scaler = torch.cuda.amp.GradScaler()\n",
    "    logger.info(f\"model {params['model_name']} create!\")\n",
    "    return optimizer, criterion, scheduler, grad_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53937ba-c14d-4e31-9edf-49ae8387964a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8034ff-ca7e-4218-8a7d-3c7bb236046b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de732aec-6615-4348-a1da-8a813ab232f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, data_loader, epoch, epochs, criterion=None):\n",
    "    start=time.time()\n",
    "    batch_time = AverageMeter(\"Time\", \":.0f\")\n",
    "    train_losses = AverageMeter(\"Loss\", \":.4e\")\n",
    "    train_nmae = AverageMeter(\"Nmae\", \":.5f\")\n",
    "\n",
    "    model.train()\n",
    "    for batch in tqdm(data_loader): # set_postfix\n",
    "        inputs = batch[0].float().cuda(non_blocking=True)\n",
    "        metas = batch[1].float().cuda(non_blocking=True)\n",
    "        targets = batch[2].float().cuda(non_blocking=True).squeeze()\n",
    "\n",
    "        if params[\"mixup\"] and epoch < params[\"mixup_end_epoch\"]:\n",
    "            inputs, targets_a, targets_b, lam = mixup_data(inputs, targets, params[\"mixup_alpha\"])\n",
    "\n",
    "        elif params[\"cutmix\"]:\n",
    "            inputs, targets_a, targets_b, lam = cutmix(inputs, targets)\n",
    "\n",
    "        if \"sam\" in params[\"optimizer\"]:\n",
    "            # first forward-backward step\n",
    "            enable_running_stats(model)\n",
    "            # with torch.cuda.amp.autocast():\n",
    "            if \"ib\" in params[\"criterion\"]:\n",
    "                outputs, features = model(inputs)\n",
    "            else:\n",
    "                outputs = model(inputs, metas).squeeze()\n",
    "            if (params[\"mixup\"] and epoch < params[\"mixup_end_epoch\"]) or params[\"cutmix\"]:\n",
    "                if \"ib\" in params[\"criterion\"] and epoch > params[\"ib_start_epoch\"]:\n",
    "                    loss = mix_criterion(\"ib\", (outputs, features), targets_a, targets_b, lam)\n",
    "                else:\n",
    "                    loss = mix_criterion(\"cr\", outputs, targets_a, targets_b, lam)\n",
    "            else:\n",
    "                if \"ib\" in params[\"criterion\"] and epoch > params[\"ib_start_epoch\"]:\n",
    "                    loss = criterion_ib((outputs, features), targets)\n",
    "                else:\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    # loss = torch.mean(criterion.lossfun((outputs - targets)[:,None]))\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), params[\"max_norm\"])\n",
    "            optimizer.first_step(zero_grad=True)\n",
    "\n",
    "            # second forward-backward step\n",
    "            disable_running_stats(model)\n",
    "            # with torch.cuda.amp.autocast():\n",
    "            if (params[\"mixup\"] and epoch < params[\"mix_end_epoch\"]) or (params[\"cutmix\"] and epoch < params[\"mix_end_epoch\"]):\n",
    "                if \"ib\" in params[\"criterion\"]:\n",
    "                    if epoch > params[\"ib_start_epoch\"]:\n",
    "                        second_loss = mix_criterion(\"ib\", model(inputs), targets_a, targets_b, lam)\n",
    "                    else:\n",
    "                        second_loss = mix_criterion(\"cr\", model(inputs)[0], targets_a, targets_b, lam)\n",
    "                else:\n",
    "                    second_loss = mix_criterion(\"cr\", model(inputs), targets_a, targets_b, lam)\n",
    "            else:\n",
    "                if \"ib\" in params[\"criterion\"]:\n",
    "                    if epoch > params[\"ib_start_epoch\"]:\n",
    "                        second_loss = criterion_ib(model(inputs), targets)\n",
    "                    else:\n",
    "                        second_loss = criterion(model(inputs)[0], targets)\n",
    "                else:\n",
    "                    second_loss = criterion(model(inputs, metas).squeeze(1), targets)\n",
    "                    # second_loss = torch.mean(criterion.lossfun((model(inputs, metas).squeeze(1) - targets)[:,None]))\n",
    "            second_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), params[\"max_norm\"])\n",
    "            optimizer.second_step(zero_grad=True)\n",
    "\n",
    "        else:\n",
    "            optimizer.zero_grad()\n",
    "            with torch.cuda.amp.autocast():\n",
    "                if \"ib\" in params[\"criterion\"]:\n",
    "                    outputs, features = model(inputs)\n",
    "                else:\n",
    "                    outputs = model(inputs, metas).squeeze()\n",
    "                if (params[\"mixup\"] and epoch < params[\"mix_end_epoch\"]) or (params[\"cutmix\"] and epoch < params[\"mix_end_epoch\"]):\n",
    "                    if \"ib\" in params[\"criterion\"] and epoch > params[\"ib_start_epoch\"]:\n",
    "                        loss = mix_criterion(\"ib\", (outputs, features), targets_a, targets_b, lam)\n",
    "                    else:\n",
    "                        loss = mix_criterion(\"cr\", outputs, targets_a, targets_b, lam)\n",
    "                else:\n",
    "                    if \"ib\" in params[\"criterion\"] and epoch > params[\"ib_start_epoch\"]:\n",
    "                        loss = criterion_ib((outputs, features), targets)\n",
    "                    else:\n",
    "                        loss = criterion(outputs, targets)\n",
    "                        # loss = torch.mean(criterion.lossfun((outputs - targets)[:,None]))\n",
    "            grad_scaler.scale(loss).backward()\n",
    "            grad_scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), params[\"max_norm\"])\n",
    "            grad_scaler.step(optimizer)\n",
    "            grad_scaler.update()\n",
    "\n",
    "        # outputs = torch.stack([outputs[\"image\"], outputs[\"meta\"]], dim=1).mean(dim=1).squeeze(1)\n",
    "        train_losses.update(loss.item(), inputs.size(0))\n",
    "        train_nmae.update(get_nmae(outputs.detach().cpu().numpy(), targets.detach().cpu().numpy()), inputs.size(0))\n",
    "\n",
    "    if \"ib\" in params[\"criterion\"] and epoch >= params[\"ib_start_epoch\"]:\n",
    "        adjust_learning_rate(optimizer.base_optimizer, epoch)\n",
    "    else:\n",
    "        scheduler.step()\n",
    "\n",
    "    batch_time.update(time.time() - start)\n",
    "    train_log = f\"epoch : {epoch+1}/{epochs} | time : {batch_time.val:.0f}s/{batch_time.val*(epochs-epoch-1):.0f}s | TRAIN | loss : {train_losses.avg:.5f} | nmae : {train_nmae.avg:.5f}\"\n",
    "    logger.info(train_log)\n",
    "    return train_losses.avg, train_nmae.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e24534-f9ab-4dc2-acb9-c01bbe7aca5a",
   "metadata": {},
   "source": [
    "## val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2950fdc-0010-4a8b-9139-4ff25c1c8188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, optimizer, data_loader, epoch, epochs, criterion=None):\n",
    "    start = time.time()\n",
    "    val_batch_time = AverageMeter(\"Time\", \":.0f\")\n",
    "    val_losses = AverageMeter(\"Loss\", \":.4e\")\n",
    "    val_correct = AverageMeter(\"Acc\", \":.5f\")\n",
    "    val_nmae = AverageMeter(\"Nmae\", \":.5f\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader):                              \n",
    "            inputs = batch[0].float().cuda(non_blocking=True)\n",
    "            metas = batch[1].float().cuda(non_blocking=True)\n",
    "            targets = batch[2].long().cuda(non_blocking=True).squeeze()\n",
    "            # with torch.cuda.amp.autocast():\n",
    "            if \"ib\" in params[\"criterion\"]:\n",
    "                outputs, features = model(inputs)\n",
    "            else:\n",
    "                outputs = model(inputs, metas).squeeze()\n",
    "            if \"ib\" in params[\"criterion\"] and epoch > params[\"ib_start_epoch\"]:\n",
    "                loss = criterion_ib((outputs, features), targets)\n",
    "            else:\n",
    "                loss = criterion(outputs, targets)\n",
    "                # loss = torch.mean(criterion.lossfun((outputs - targets)[:,None]))\n",
    "\n",
    "            val_losses.update(loss.item(), inputs.size(0))\n",
    "            val_nmae.update(get_nmae(outputs.detach().cpu().numpy(), targets.detach().cpu().numpy()), inputs.size(0))\n",
    "    # torch.save(model.state_dict(), SAVE_PATH+params[\"model_name\"]+\"_last.pt\")\n",
    "\n",
    "    val_batch_time.update(time.time() - start)\n",
    "    val_log = f\"epoch : {epoch+1}/{epochs} | time : {val_batch_time.val:.0f}s/{val_batch_time.val*(epochs-epoch-1):.0f}s | VAL | loss : {val_losses.avg:.5f} | nmae : {val_nmae.avg:.5f}\"\n",
    "    logger.info(val_log)\n",
    "    return val_losses.avg, val_nmae.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2daf23e-6496-4a86-a945-76d5aa1e0e3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Start Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba30339-2b1b-427c-9160-3b9170dab82b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-20 16:46:58] KFold5 Start!! Current -> 0\n",
      "[2022-05-20 16:47:00] model tf_efficientnetv2_b0 create!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.6000e-01.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee84ebee18c747049130d1fec53b84b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-20 16:47:26] epoch : 1/25 | time : 26s/623s | TRAIN | loss : 73.73714 | nmae : 0.90999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.5937e-01.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ebe047eac3d40e5a7fe1092cbb984ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-20 16:47:33] epoch : 1/25 | time : 7s/159s | VAL | loss : 67.74374 | nmae : 0.90993\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36258deb2cc54a36bc3e8074f6cbbef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-20 16:47:58] epoch : 2/25 | time : 26s/588s | TRAIN | loss : 73.30623 | nmae : 0.90559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.5749e-01.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f66530003e4dc19bcbcecf7b7b7dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-20 16:48:05] epoch : 2/25 | time : 6s/147s | VAL | loss : 63.73503 | nmae : 0.85627\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2edec8aa0e904a8fa65bba130601e903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-20 16:48:30] epoch : 3/25 | time : 26s/561s | TRAIN | loss : 67.15659 | nmae : 0.83030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.5438e-01.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b0fd0a17144f62bf5917587aa62af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-20 16:48:37] epoch : 3/25 | time : 6s/143s | VAL | loss : 64.31225 | nmae : 0.86704\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332f2a0f70e94e4899d99eec0ae55ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-20 16:49:02] epoch : 4/25 | time : 25s/535s | TRAIN | loss : 73.26136 | nmae : 0.90608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.5010e-01.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0a37d8ef61451187f834eed441205c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-20 16:49:09] epoch : 4/25 | time : 6s/134s | VAL | loss : 62.61366 | nmae : 0.83400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb730fab99f7447fae2d7a84ea867c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, shuffle=True, random_state=params[\"seed\"])\n",
    "\n",
    "for idx, (train_idx, val_idx) in enumerate(cv.split(train_data_list)):\n",
    "    logger.info(f\"KFold5 Start!! Current -> {idx}\")\n",
    "    best_nmae = 9999\n",
    "    train_dataset = np.array(train_data_list)[train_idx]\n",
    "    val_dataset = np.array(train_data_list)[val_idx]\n",
    "\n",
    "    train_dataset = CustomDataset(train_dataset, mode=\"train\", transform=train_transform, scaler=scaler, imputer=imputer)\n",
    "    train_loader = DataLoader(\n",
    "                        train_dataset,\n",
    "                        batch_size=params[\"batch\"],\n",
    "                        shuffle=True,\n",
    "                        pin_memory=True,\n",
    "                        num_workers=params[\"num_workers\"])\n",
    "\n",
    "    val_dataset = CustomDataset(val_dataset, mode=\"train\", transform=test_transform, scaler=scaler, imputer=imputer)\n",
    "    val_loader = DataLoader(\n",
    "                        val_dataset,\n",
    "                        batch_size=params[\"batch\"],\n",
    "                        shuffle=True,\n",
    "                        pin_memory=True,\n",
    "                        num_workers=params[\"num_workers\"])\n",
    "    \n",
    "    model = Network()\n",
    "    if idx == 0:\n",
    "        neptune_run[\"model_classifier\"].log(model.classifier)\n",
    "    model.to(DEVICE)\n",
    "    optimizer, criterion, scheduler, grad_scaler = set_optimizer()\n",
    "    for epoch in range(params[\"epochs\"]):\n",
    "        train_losses, train_nmae = train(model=model, optimizer=optimizer, data_loader=train_loader, epoch=epoch, epochs=params[\"epochs\"], criterion=criterion)\n",
    "        val_losses, val_nmae = val(model=model, optimizer=optimizer, data_loader=val_loader, epoch=epoch, epochs=params[\"epochs\"], criterion=criterion)\n",
    "        \n",
    "        neptune_run[f\"KFold{idx}_train/loss\"].log(train_losses)\n",
    "        neptune_run[f\"KFold{idx}_train/nmae\"].log(train_nmae)\n",
    "        neptune_run[f\"KFold{idx}_val/loss\"].log(val_losses)\n",
    "        neptune_run[f\"KFold{idx}_val/nmae\"].log(val_nmae)\n",
    "        if val_nmae <= best_nmae:\n",
    "            best_nmae = val_nmae\n",
    "            torch.save(model.state_dict(), SAVE_PATH+params[\"model_name\"]+f\"_best{idx}.pt\")\n",
    "            if best_nmae == 0:\n",
    "                logger.info(\"best_loss is 0!!\")\n",
    "                break\n",
    "        torch.save(model.state_dict(), SAVE_PATH+params[\"model_name\"]+f\"_last{idx}.pt\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171bf760-d7c3-4988-8cc6-1b3a3ad5b418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f4ccd4-26b6-4e1c-91c2-229c456eff5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2241024-d33e-4a2c-bb47-3d891d5388cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1eaecb-95ae-468f-9c36-c804b81b0f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_list = get_test_data(TEST_PATH)\n",
    "test_dataset = CustomDataset(test_data_list, mode=\"test\", transform=test_transform, scaler=scaler, imputer=imputer)\n",
    "test_loader = DataLoader(\n",
    "                    test_dataset,\n",
    "                    batch_size=params[\"batch\"]//2,\n",
    "                    shuffle=False,\n",
    "                    pin_memory=True,\n",
    "                    num_workers=params[\"num_workers\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f654652d-9f56-443e-8167-d120707c1d38",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90b8784-3ca4-4769-bbce-85e48bf64b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# tta_transform = tta.Compose(\n",
    "#     [\n",
    "#         # tta.HorizontalFlip(),\n",
    "#         # tta.VerticalFlip(),\n",
    "#         tta.Rotate90(angles=[0, 90, 180, 270]),\n",
    "#         # tta.Scale(scales=[0.6, 0.8, 1]),\n",
    "#         # tta.Multiply(factors=[0.9, 1, 1.1]),        \n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9dadd0-6362-4ab1-bf4c-aab8e5175f6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f9ba6c-ea8e-41ff-b4c9-e872f6fd4c77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_ensemble = []\n",
    "for i in range(1):\n",
    "    model = Network(mode=\"test\")\n",
    "    model.load_state_dict(torch.load(SAVE_PATH+params[\"model_name\"]+f\"_best{i}.pt\"))\n",
    "    model.to(DEVICE)\n",
    "    # tta_model = tta.ClassificationTTAWrapper(model, tta_transform)\n",
    "\n",
    "    model.eval()\n",
    "    f_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            inputs = batch[0].float().cuda(non_blocking=True)\n",
    "            metas = batch[1].float().cuda(non_blocking=True)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                # outputs = tta_model(x)\n",
    "                outputs = model(inputs, metas).squeeze()\n",
    "            f_pred.extend(outputs.detach().cpu().numpy().tolist())\n",
    "\n",
    "    # Pred Ensemble\n",
    "    pred_ensemble.append(f_pred)\n",
    "\n",
    "f_result = np.mean(pred_ensemble, axis=0)\n",
    "\n",
    "# Submission\n",
    "submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "submission[\"leaf_weight\"] = f_result\n",
    "submission.to_csv(SAVE_PATH+\"submission.csv\", index = False)\n",
    "neptune_run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f54d4e-0bbb-4d70-aea3-a0ada0980625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
