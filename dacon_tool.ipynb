{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55c79ae4-2c18-45f1-9607-e9f49a43119b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea90d00-c161-42ee-afd8-387151307817",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.transformer import _get_activation_fn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, Sampler\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.ops import FeaturePyramidNetwork, DeformConv2d\n",
    "\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from RandAugment import RandAugment\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import torch_optimizer as optim\n",
    "import ttach as tta\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b9a38c-12cb-4b43-b008-3fb2dfcb0b69",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a675ab-087c-477c-9085-e910f7a617c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "NUM_CLASS = 88\n",
    "EPOCHS = 100\n",
    "BATCH = 16\n",
    "LR = 1e-4\n",
    "WD = 5e-2\n",
    "MOMENTUM = 0.9\n",
    "DROP_OUT_RATE = 0.5\n",
    "DROP_PATH_RATE = 0\n",
    "MAX_NORM = 1\n",
    "NUM_WORKERS = 4\n",
    "IMAGE_SIZE = 448\n",
    "TEST_IMAGE_SIZE = 448\n",
    "\n",
    "IB_START_EPOCH = 999#EPOCHS//2\n",
    "MIXUP_END_EPOCH = -1 # EPOCHS//2 - 5\n",
    "MIXUP_ALPHA = 0.2\n",
    "\n",
    "# MODEL_NAME = \"tf_efficientnetv2_m_in21ft1k\"\n",
    "# MODEL_NAME = \"tf_efficientnet_b3_ns\"\n",
    "# MODEL_NAME = \"swin_large_patch4_window12_384\"\n",
    "# MODEL_NAME = \"swin_s3_tiny_224\"\n",
    "MODEL_NAME = \"tresnet_l_448\"\n",
    "MODEL_WEIGHT_NAME = f\"{MODEL_NAME}_{EPOCHS}epochs_{BATCH}batchsize_{IMAGE_SIZE}imagesize_{TEST_IMAGE_SIZE}testimagesize_{LR}lr\"\n",
    "SAVE_FILE_NAME = f\"{MODEL_NAME}_{EPOCHS}epochs_{BATCH}batchsize_{IMAGE_SIZE}imagesize_{TEST_IMAGE_SIZE}testimagesize_{LR}lr.csv\"\n",
    "\n",
    "TRAIN_FILE = \"data/train_df.csv\"\n",
    "TEST_FILE = \"data/test_df.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ea0c05-db43-4aa7-b607-d4b56be81231",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31c203d-052e-41e9-8728-46ba5642fd40",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Mean, Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf29174-f3ec-4bcd-9f7f-8e3debcef07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnlineMeanStd:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, dataset, batch_size, method='strong'):\n",
    "        \"\"\"\n",
    "        Calculate mean and std of a dataset in lazy mode (online)\n",
    "        On mode strong, batch size will be discarded because we use batch_size=1 to minimize leaps.\n",
    "        :param dataset: Dataset object corresponding to your dataset\n",
    "        :param batch_size: higher size, more accurate approximation\n",
    "        :param method: weak: fast but less accurate, strong: slow but very accurate - recommended = strong\n",
    "        :return: A tuple of (mean, std) with size of (3,)\n",
    "        \"\"\"\n",
    "\n",
    "        if method == 'weak':\n",
    "            loader = DataLoader(dataset=dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False,\n",
    "                                num_workers=1,\n",
    "                                pin_memory=0)\n",
    "            mean = 0.\n",
    "            std = 0.\n",
    "            nb_samples = 0.\n",
    "            for data in loader:\n",
    "                data = data[0]\n",
    "                batch_samples = data.size(0)\n",
    "                data = data.view(batch_samples, data.size(1), -1)\n",
    "                mean += data.mean(2).sum(0)\n",
    "                std += data.std(2).sum(0)\n",
    "                nb_samples += batch_samples\n",
    "\n",
    "            mean /= nb_samples\n",
    "            std /= nb_samples\n",
    "\n",
    "            return mean, std\n",
    "\n",
    "        elif method == 'strong':\n",
    "            loader = DataLoader(dataset=dataset,\n",
    "                                batch_size=1,\n",
    "                                shuffle=False,\n",
    "                                num_workers=1,\n",
    "                                pin_memory=0)\n",
    "            cnt = 0\n",
    "            fst_moment = torch.empty(3)\n",
    "            snd_moment = torch.empty(3)\n",
    "\n",
    "            for data in loader:\n",
    "                data = data\n",
    "                b, c, h, w = data.shape\n",
    "                nb_pixels = b * h * w\n",
    "                sum_ = torch.sum(data, dim=[0, 2, 3])\n",
    "                sum_of_square = torch.sum(data ** 2, dim=[0, 2, 3])\n",
    "                fst_moment = (cnt * fst_moment + sum_) / (cnt + nb_pixels)\n",
    "                snd_moment = (cnt * snd_moment + sum_of_square) / (cnt + nb_pixels)\n",
    "\n",
    "                cnt += nb_pixels\n",
    "\n",
    "            return fst_moment, torch.sqrt(snd_moment - fst_moment ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f937d59-e03e-4b92-b7af-8f2a0d759b16",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68df44ee-d2a5-4952-8de0-ebcae1302884",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 df,\n",
    "                 mode,\n",
    "                 mean=[0.485, 0.456, 0.406],\n",
    "                 std=[0.229, 0.224, 0.225]):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.mode = mode\n",
    "        self.data = df\n",
    "        if self.mode == \"train\":\n",
    "            lbs = []\n",
    "            for l in self.data[\"label\"]:\n",
    "                lbs.append(LABEL_ENCODER[l])\n",
    "            self.labels = lbs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "            name = self.data[\"file_name\"][index]\n",
    "            image = cv2.imread(f\"data/{self.mode}/{name}\")\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            if self.mode == \"train\":\n",
    "                label = LABEL_ENCODER[self.data[\"label\"][index]]\n",
    "                image = self.input_transform(image, LABEL_DECODER[label])[\"image\"]\n",
    "                return image, label\n",
    "            image = self.input_transform(image)[\"image\"]\n",
    "            return image\n",
    "        \n",
    "    def input_transform(self, image, label=None):\n",
    "        if self.mode == \"train\":\n",
    "            if \"metal_nut\" in label:\n",
    "                flip_p = 0\n",
    "            else:\n",
    "                flip_p = 0.5\n",
    "            transform = A.Compose([\n",
    "                            A.Resize(IMAGE_SIZE, IMAGE_SIZE, interpolation=cv2.INTER_AREA),\n",
    "                            # A.RandomCrop(IMAGE_SIZE, IMAGE_SIZE, p=1),\n",
    "                            A.RandomRotate90(p=0.5),\n",
    "                            A.HorizontalFlip(p=flip_p),\n",
    "                            A.VerticalFlip(p=flip_p),\n",
    "                            A.Affine(rotate=(-45, 45), translate_percent=(-0.1, 0.1), p=0.5),\n",
    "                            A.Cutout(num_holes=16, p=0.5),\n",
    "                            # A.GaussNoise(p=0.5),\n",
    "                            # A.RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "                            A.Normalize(\n",
    "                                mean = [0.4330, 0.4034, 0.3941],\n",
    "                                std = [0.2602, 0.2572, 0.2535],\n",
    "                            ),\n",
    "                            ToTensorV2()\n",
    "                        ])\n",
    "            return transform(image=image)\n",
    "        \n",
    "        elif self.mode == \"test\":\n",
    "            transform = A.Compose([\n",
    "                            A.Resize(TEST_IMAGE_SIZE, TEST_IMAGE_SIZE, interpolation=cv2.INTER_AREA),\n",
    "                            A.Normalize(\n",
    "                                mean = [0.4183, 0.3931, 0.3866],\n",
    "                                std = [0.2604, 0.2585, 0.2562]\n",
    "                            ),\n",
    "                            ToTensorV2(),\n",
    "                        ])\n",
    "            return transform(image=image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b466d3e-487d-4b01-a440-acbbc0637d04",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d984b93a-66c6-4c98-8731-beb93b817dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCycleIter:\n",
    "    \n",
    "    def __init__ (self, data, test_mode=False):\n",
    "        self.data_list = list(data)\n",
    "        self.length = len(self.data_list)\n",
    "        self.i = self.length - 1\n",
    "        self.test_mode = test_mode\n",
    "        \n",
    "    def __iter__ (self):\n",
    "        return self\n",
    "    \n",
    "    def __next__ (self):\n",
    "        self.i += 1\n",
    "        \n",
    "        if self.i == self.length:\n",
    "            self.i = 0\n",
    "            if not self.test_mode:\n",
    "                random.shuffle(self.data_list)\n",
    "            \n",
    "        return self.data_list[self.i]\n",
    "    \n",
    "def class_aware_sample_generator (cls_iter, data_iter_list, n, num_samples_cls=1, is_infinite=False):\n",
    "\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i < n or is_infinite:\n",
    "        \n",
    "        if j >= num_samples_cls:\n",
    "            j = 0\n",
    "    \n",
    "        if j == 0:\n",
    "            temp_tuple = next(zip(*[data_iter_list[next(cls_iter)]]*num_samples_cls))\n",
    "            yield temp_tuple[j]\n",
    "        else:\n",
    "            yield temp_tuple[j]\n",
    "        \n",
    "        i += 1\n",
    "        j += 1\n",
    "\n",
    "class ClassAwareSampler (Sampler):\n",
    "    \n",
    "    def __init__(self, data_source, num_samples_cls=1, is_infinite=False):\n",
    "        num_classes = len(np.unique(data_source.labels))\n",
    "        self.class_iter = RandomCycleIter(range(num_classes))\n",
    "        cls_data_list = [list() for _ in range(num_classes)]\n",
    "        for i, label in enumerate(data_source.labels):\n",
    "            cls_data_list[label].append(i)\n",
    "        self.data_iter_list = [RandomCycleIter(x) for x in cls_data_list]\n",
    "        self.num_samples = max([len(x) for x in cls_data_list]) * len(cls_data_list)\n",
    "        self.num_samples_cls = num_samples_cls\n",
    "\n",
    "        self.is_infinite = is_infinite\n",
    "        \n",
    "    def __iter__ (self):\n",
    "        return class_aware_sample_generator(self.class_iter, self.data_iter_list,\n",
    "                                            self.num_samples, self.num_samples_cls, self.is_infinite)\n",
    "    \n",
    "    def __len__ (self):\n",
    "        return self.num_samples\n",
    "    \n",
    "def get_sampler():\n",
    "    return ClassAwareSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9daded-7e85-4fcb-af96-5c93589f9be8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b8a86c-6711-4545-abf0-e8ff99bd06b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cosine CrossEntropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c477ca-97a5-41b0-a5a1-98b45ed77d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, xent=.1, reduction=\"mean\", weight=None):\n",
    "        super(CosineCrossEntropyLoss, self).__init__()\n",
    "        self.xent = xent\n",
    "        self.reduction = reduction\n",
    "        self.weight = weight\n",
    "        self.y = torch.Tensor([1]).cuda()\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        cosine_loss = F.cosine_embedding_loss(input, F.one_hot(target, num_classes=input.size(-1)), self.y, reduction=self.reduction)\n",
    "        cent_loss = F.cross_entropy(F.normalize(input), target, reduction=self.reduction, weight=self.weight)\n",
    "        \n",
    "        return cosine_loss + self.xent * cent_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4943a11-7aff-42e9-ae79-443e0412e88b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cosine Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8b23c7-65ff-4668-83a1-3eca238cbc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalCosineLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2, xent=.1, reduction=\"mean\", weight=None):\n",
    "        super(FocalCosineLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.xent = xent\n",
    "        self.y = torch.Tensor([1]).cuda()\n",
    "        self.reduction = reduction\n",
    "        self.weight = weight\n",
    "\n",
    "    def forward(self, input, target, reduction=\"mean\"):\n",
    "        cosine_loss = F.cosine_embedding_loss(input, F.one_hot(target, num_classes=input.size(-1)), self.y, reduction=self.reduction)\n",
    "\n",
    "        cent_loss = F.cross_entropy(F.normalize(input), target, reduction=self.reduction, weight=self.weight)\n",
    "        pt = torch.exp(-cent_loss)\n",
    "        focal_loss = self.alpha * (1-pt)**self.gamma * cent_loss\n",
    "\n",
    "        if self.reduction == \"mean\":\n",
    "            focal_loss = torch.mean(focal_loss)\n",
    "\n",
    "        return cosine_loss + self.xent * focal_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace1ffa2-23a8-4c1f-90b4-18322512cde9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Seesaw Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbd0ffd-8f1e-423d-a3e8-776d7b9a9fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeesawLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of seesaw loss.\n",
    "    Refers to `Seesaw Loss for Long-Tailed Instance Segmentation (CVPR 2021)\n",
    "    <https://arxiv.org/abs/2008.10032>\n",
    "    Args:\n",
    "        num_classes (int): The number of classes.\n",
    "                Default to 1000 for the ImageNet dataset.\n",
    "        p (float): The ``p`` in the mitigation factor.\n",
    "                Defaults to 0.8.\n",
    "        q (float): The ``q`` in the compensation factor.\n",
    "                Defaults to 2.0.\n",
    "        eps (float): The min divisor to smooth the computation of compensation factor.\n",
    "                Default to 1e-2.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=NUM_CLASS,\n",
    "                 p=0.8, q=1.0, eps=1e-2):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "        self.eps = eps\n",
    "\n",
    "        # cumulative samples for each category\n",
    "        self.register_buffer('accumulated',\n",
    "                             torch.zeros(self.num_classes, dtype=torch.float))\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        # accumulate the samples for each category\n",
    "        for unique in targets.unique():\n",
    "            self.accumulated[unique] += (targets == unique.item()).sum()\n",
    "\n",
    "        onehot_targets = F.one_hot(targets, self.num_classes)\n",
    "        seesaw_weights = outputs.new_ones(onehot_targets.size())\n",
    "\n",
    "        # mitigation factor\n",
    "        if self.p > 0:\n",
    "            matrix = self.accumulated[None, :].clamp(min=1) / self.accumulated[:, None].clamp(min=1)\n",
    "            index = (matrix < 1.0).float()\n",
    "            sample_weights = matrix.pow(self.p) * index + (1 - index)\n",
    "            mitigation_factor = sample_weights[targets.long(), :]\n",
    "            seesaw_weights = seesaw_weights * mitigation_factor\n",
    "\n",
    "        # compensation factor\n",
    "        if self.q > 0:\n",
    "            scores = F.softmax(outputs.detach(), dim=1)\n",
    "            self_scores = scores[torch.arange(0, len(scores)).to(scores.device).long(), targets.long()]\n",
    "            score_matrix = scores / self_scores[:, None].clamp(min=self.eps)\n",
    "            index = (score_matrix > 1.0).float()\n",
    "            compensation_factor = score_matrix.pow(self.q) * index + (1 - index)\n",
    "            seesaw_weights = seesaw_weights * compensation_factor\n",
    "\n",
    "        outputs = outputs + (seesaw_weights.log() * (1 - onehot_targets))\n",
    "        return F.cross_entropy(outputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4197eec6-3cb5-49c6-9552-7658cd5d55d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfce20a-2a36-4d85-b2c7-ae7107b5585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, label_smoothing=0.1, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = nn.CrossEntropyLoss(label_smoothing=self.label_smoothing)(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf8b9d1-d4a7-4fbd-ba53-4683bc74e97e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CDB Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f7eab-3be2-4fc0-895a-2419df5403ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return (1/(1+np.exp(-x)))\n",
    "\n",
    "class CDB_loss(nn.Module):\n",
    "  \n",
    "    def __init__(self, class_difficulty, tau='dynamic', reduction='none'):\n",
    "        \n",
    "        super(CDB_loss, self).__init__()\n",
    "        self.class_difficulty = class_difficulty\n",
    "        if tau == 'dynamic':\n",
    "            bias = (1 - np.min(class_difficulty))/(1 - np.max(class_difficulty) + 0.01)\n",
    "            tau = sigmoid(bias)\n",
    "        else:\n",
    "            tau = float(tau) \n",
    "        self.weights = self.class_difficulty ** tau\n",
    "        self.weights = self.weights / self.weights.sum() * len(self.weights)\n",
    "        self.reduction = reduction\n",
    "        self.loss = nn.CrossEntropyLoss(weight=torch.FloatTensor(self.weights), reduction=self.reduction).cuda()\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        return self.loss(input, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb758fd-4dbe-4a7d-93f5-09dc41a56a70",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CB Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d501d9e-0a8e-4501-8862-bb01461f60df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CB_loss(labels, logits, samples_per_cls, no_of_classes, loss_type, beta, gamma, device):\n",
    "    effective_num = 1.0 - np.power(beta, samples_per_cls)\n",
    "    weights = (1.0 - beta) / np.array(effective_num)\n",
    "    weights = weights / np.sum(weights) * no_of_classes\n",
    "\n",
    "    labels_one_hot = F.one_hot(labels, no_of_classes).float()\n",
    "    labels_one_hot = labels_one_hot.to(device)\n",
    "\n",
    "    weights = torch.tensor(weights).float()\n",
    "    weights = weights.unsqueeze(0)\n",
    "    weights = weights.repeat(labels_one_hot.shape[0],1).to(device)\n",
    "    weights = weights* labels_one_hot\n",
    "    weights = weights.sum(1)\n",
    "    weights = weights.unsqueeze(1)\n",
    "    weights = weights.repeat(1,no_of_classes)\n",
    "\n",
    "    if loss_type == \"focal\":\n",
    "        cb_loss = focal_loss(labels_one_hot, logits, weights, gamma)\n",
    "    elif loss_type == \"sigmoid\":\n",
    "        cb_loss = F.binary_cross_entropy_with_logits(input = logits,target = labels_one_hot, weights = weights)\n",
    "    elif loss_type == \"softmax\":\n",
    "        pred = logits.softmax(dim = 1)\n",
    "        cb_loss = F.binary_cross_entropy(input = pred, target = labels_one_hot, weight = weights)\n",
    "    return cb_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac45901-e9f0-4524-81b2-9c0221c238da",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Equalized Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba620ec-512f-4ec9-8e67-bd67cae53058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalized_focal_loss(logits,\n",
    "                         targets,\n",
    "                         gamma_b=2,\n",
    "                         scale_factor=8,\n",
    "                         reduction=\"mean\"):\n",
    "    \"\"\" EFL loss\"\"\"\n",
    "    ce_loss = F.cross_entropy(logits, targets, reduction=\"none\", label_smoothing=0.1)\n",
    "    outputs = F.cross_entropy(logits, targets, label_smoothing=0.1)\n",
    "    log_pt = -ce_loss\n",
    "    pt = torch.exp(log_pt)\n",
    "\n",
    "    targets = targets.view(-1, 1)\n",
    "    grad_i = torch.autograd.grad(outputs=-outputs, inputs=logits)[0]\n",
    "    grad_i = grad_i.gather(1, targets)\n",
    "    pos_grad_i = F.relu(grad_i).sum()\n",
    "    neg_grad_i = F.relu(-grad_i).sum()\n",
    "    neg_grad_i += 1e-9\n",
    "    grad_i = pos_grad_i / neg_grad_i\n",
    "    grad_i = torch.clamp(grad_i, min=0, max=1)\n",
    "\n",
    "    dy_gamma = gamma_b + scale_factor * (1 - grad_i)\n",
    "    dy_gamma = dy_gamma.view(-1)\n",
    "    # weighting factor\n",
    "    wf = dy_gamma / gamma_b\n",
    "    weights = wf * (1 - pt) ** dy_gamma\n",
    "\n",
    "    efl = weights * ce_loss\n",
    "\n",
    "    if reduction == \"sum\":\n",
    "        efl = efl.sum()\n",
    "    elif reduction == \"mean\":\n",
    "        efl = efl.mean()\n",
    "    else:\n",
    "        raise ValueError(f\"reduction '{reduction}' is not valid\")\n",
    "    return efl\n",
    "\n",
    "\n",
    "def balanced_equalized_focal_loss(logits,\n",
    "                                  targets,\n",
    "                                  alpha_t=0.25,\n",
    "                                  gamma_b=2,\n",
    "                                  scale_factor=8,\n",
    "                                  reduction=\"mean\"):\n",
    "    \"\"\"balanced EFL loss\"\"\"\n",
    "    return alpha_t * equalized_focal_loss(logits, targets, gamma_b,\n",
    "                                          scale_factor, reduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd5b988-bc5a-4a5c-8926-14893de92309",
   "metadata": {
    "tags": []
   },
   "source": [
    "### IB Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f6a4ed-f82b-4a9d-8f13-fe40752bd735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ib_loss(input_values, ib):\n",
    "    \"\"\"Computes the focal loss\"\"\"\n",
    "    loss = input_values * ib\n",
    "    return loss.mean()\n",
    "\n",
    "class IBLoss(nn.Module):\n",
    "    def __init__(self, weight=None, alpha=10000.):\n",
    "        super(IBLoss, self).__init__()\n",
    "        assert alpha > 0\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = 0.001\n",
    "        self.weight = weight\n",
    "\n",
    "    def forward(self, outputs, target):\n",
    "        input, features = outputs\n",
    "        grads = torch.sum(torch.abs(F.softmax(input, dim=1) - F.one_hot(target, NUM_CLASS)),1) # N * 1\n",
    "        ib = grads*features.reshape(-1)\n",
    "        ib = self.alpha / (ib + self.epsilon)\n",
    "        return ib_loss(F.cross_entropy(input, target, reduction='none', weight=self.weight), ib)\n",
    "\n",
    "\n",
    "def ib_focal_loss(input_values, ib, gamma):\n",
    "    \"\"\"Computes the ib focal loss\"\"\"\n",
    "    p = torch.exp(-input_values)\n",
    "    loss = (1 - p) ** gamma * input_values * ib\n",
    "    return loss.mean()\n",
    "\n",
    "class IB_FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None, alpha=10000., gamma=0.):\n",
    "        super(IB_FocalLoss, self).__init__()\n",
    "        assert alpha > 0\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = 0.001\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, outputs, target):\n",
    "        input, features = outputs\n",
    "        grads = torch.sum(torch.abs(F.softmax(input, dim=1) - F.one_hot(target, NUM_CLASS)),1) # N * 1\n",
    "        ib = grads*(features.reshape(-1))\n",
    "        ib = self.alpha / (ib + self.epsilon)\n",
    "        return ib_focal_loss(F.cross_entropy(input, target, reduction='none', weight=self.weight), ib, self.gamma) # weight=self.weight\n",
    "    \n",
    "    \n",
    "class IB_CosineFocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None, alpha=10000., gamma=0.):\n",
    "        super(IB_CosineFocalLoss, self).__init__()\n",
    "        assert alpha > 0\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = 0.001\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, outputs, target):\n",
    "        input, features = outputs\n",
    "        grads = torch.sum(torch.abs(F.softmax(input, dim=1) - F.one_hot(target, NUM_CLASS)),1) # N * 1\n",
    "        ib = grads*(features.reshape(-1))\n",
    "        ib = self.alpha / (ib + self.epsilon)\n",
    "        cosine_ce = CosineCrossEntropyLoss(reduction='none', weight=self.weight).cuda()\n",
    "        return ib_focal_loss(cosine_ce(input, target), ib, self.gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f573c0a3-c4c7-4781-9fc8-15e552fbbc5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Smooth Crossentropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088c6dbc-72ca-4851-b822-e01f76e3b727",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothCrossentropy(nn.Module):\n",
    "    def __init__(self, smoothing=0.1):\n",
    "        super(SmoothCrossentropy, self).__init__()\n",
    "        self.smoothing=smoothing\n",
    "\n",
    "    def forward(self, pred, gold):\n",
    "        n_class = pred.size(1)\n",
    "\n",
    "        one_hot = torch.full_like(pred, fill_value=self.smoothing / (n_class - 1))\n",
    "        one_hot.scatter_(dim=1, index=gold.unsqueeze(1), value=1.0 - self.smoothing)\n",
    "        log_prob = F.log_softmax(pred, dim=1)\n",
    "\n",
    "        return F.kl_div(input=log_prob, target=one_hot, reduction='none').sum(-1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec02d0ed-952f-4ea9-abc1-a12a4f1779a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Blanced Softmax Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2ee450-199d-47cb-b615-1d3dbd813a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedSoftmax(nn.Module):\n",
    "    \"\"\"\n",
    "    Balanced Softmax Loss\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(BalancedSoftmax, self).__init__()\n",
    "\n",
    "    def forward(self, input, label, reduction='mean'):\n",
    "        return balanced_softmax_loss(input, label, reduction)\n",
    "\n",
    "\n",
    "def balanced_softmax_loss(logits, labels, reduction=\"mean\", weight=None):\n",
    "    spc = torch.cuda.FloatTensor(SAMPLES_PER_CLS)\n",
    "    spc = spc.unsqueeze(0).expand(logits.shape[0], -1)\n",
    "    logits = logits + spc.log()\n",
    "    loss = F.cross_entropy(input=logits, target=labels, reduction=reduction, label_smoothing=0.1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02acfbca-763a-4f0d-9fc1-3dd2cb79cfa8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ASL loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4f79f8-1a09-4932-861a-787b3aa1e496",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASLSingleLabel(nn.Module):\n",
    "    '''\n",
    "    This loss is intended for single-label classification problems\n",
    "    '''\n",
    "    def __init__(self, gamma_pos=0, gamma_neg=4, eps=0.1, reduction='mean'):\n",
    "        super(ASLSingleLabel, self).__init__()\n",
    "\n",
    "        self.eps = eps\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=-1)\n",
    "        self.targets_classes = []\n",
    "        self.gamma_pos = gamma_pos\n",
    "        self.gamma_neg = gamma_neg\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, target):\n",
    "        '''\n",
    "        \"input\" dimensions: - (batch_size,number_classes)\n",
    "        \"target\" dimensions: - (batch_size)\n",
    "        '''\n",
    "        num_classes = inputs.size()[-1]\n",
    "        log_preds = self.logsoftmax(inputs)\n",
    "        self.targets_classes = torch.zeros_like(inputs).scatter_(1, target.long().unsqueeze(1), 1)\n",
    "\n",
    "        # ASL weights\n",
    "        targets = self.targets_classes\n",
    "        anti_targets = 1 - targets\n",
    "        xs_pos = torch.exp(log_preds)\n",
    "        xs_neg = 1 - xs_pos\n",
    "        xs_pos = xs_pos * targets\n",
    "        xs_neg = xs_neg * anti_targets\n",
    "        asymmetric_w = torch.pow(1 - xs_pos - xs_neg,\n",
    "                                 self.gamma_pos * targets + self.gamma_neg * anti_targets)\n",
    "        log_preds = log_preds * asymmetric_w\n",
    "\n",
    "        if self.eps > 0:  # label smoothing\n",
    "            self.targets_classes = self.targets_classes.mul(1 - self.eps).add(self.eps / num_classes)\n",
    "\n",
    "        # loss calculation\n",
    "        loss = - self.targets_classes.mul(log_preds)\n",
    "\n",
    "        loss = loss.sum(dim=-1)\n",
    "        if self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a9b9ce-9530-4f39-9a1d-77e051042f16",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Ldam Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226ee41d-eb88-4831-9f3b-8d85ecb8a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDAMLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, cls_num_list, max_m=0.5, weight=None, s=30):\n",
    "        super(LDAMLoss, self).__init__()\n",
    "        m_list = 1.0 / np.sqrt(np.sqrt(cls_num_list))\n",
    "        m_list = m_list * (max_m / np.max(m_list))\n",
    "        m_list = torch.cuda.FloatTensor(m_list)\n",
    "        self.m_list = m_list\n",
    "        assert s > 0\n",
    "        self.s = s\n",
    "        self.weight = weight\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        index = torch.zeros_like(x, dtype=torch.uint8)\n",
    "        index.scatter_(1, target.data.view(-1, 1), 1)\n",
    "        \n",
    "        index_float = index.type(torch.cuda.FloatTensor)\n",
    "        batch_m = torch.matmul(self.m_list[None, :], index_float.transpose(0,1))\n",
    "        batch_m = batch_m.view((-1, 1))\n",
    "        x_m = x - batch_m\n",
    "    \n",
    "        output = torch.where(index, x_m, x)\n",
    "        return F.cross_entropy(self.s*output, target, weight=self.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca68505-fba6-42e7-84c0-4162c4c40a4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Diverse Expert loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002c2314-01bf-4d6e-92fa-e4b21bd8f203",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiverseExpertLoss(nn.Module):\n",
    "    def __init__(self, cls_num_list=None, tau=5):\n",
    "        super().__init__()\n",
    "        self.base_loss = F.cross_entropy\n",
    "        prior = np.array(cls_num_list) / np.sum(cls_num_list)\n",
    "        self.prior = torch.tensor(prior).float().cuda()\n",
    "        \n",
    "        self.tau = tau \n",
    "        self.cls_num_list = cls_num_list\n",
    "\n",
    "    def inverse_prior(self, prior): \n",
    "        value, idx0 = torch.sort(prior)\n",
    "        _, idx1 = torch.sort(idx0)\n",
    "        idx2 = prior.shape[0]-1-idx1 # reverse the order\n",
    "        inverse_prior = value.index_select(0,idx2)\n",
    "        \n",
    "        return inverse_prior\n",
    "\n",
    "    def forward(self, output_logits, target):\n",
    "        loss = 0\n",
    "        \n",
    "        # Obtain logits from each expert  \n",
    "        expert1_logits = output_logits[\"base\"]\n",
    "        # expert2_logits = output_logits[\"balance\"]\n",
    "        expert3_logits = output_logits[\"inverse\"]\n",
    " \n",
    "        # Softmax loss for expert 1 \n",
    "        # loss += LDAMLoss(cls_num_list=self.cls_num_list, weight=prior)(expert1_logits, target)\n",
    "        loss += self.base_loss(expert1_logits, target)\n",
    "        \n",
    "        # Balanced Softmax loss for expert 2 \n",
    "        # expert2_logits = expert2_logits + torch.log(self.prior + 1e-9) \n",
    "        # loss += LDAMLoss(cls_num_list=self.cls_num_list)(expert2_logits, target)\n",
    "        # loss += self.base_loss(expert2_logits, target)\n",
    "        \n",
    "        # Inverse Softmax loss for expert 3\n",
    "        inverse_prior = self.inverse_prior(self.prior)\n",
    "        expert3_logits = expert3_logits + torch.log(self.prior + 1e-9) - self.tau * torch.log(inverse_prior+ 1e-9)\n",
    "        # loss += LDAMLoss(cls_num_list=self.cls_num_list)(expert3_logits, target)\n",
    "        loss += self.base_loss(expert3_logits, target)\n",
    "   \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81eda0c-1dee-408b-b969-a439e43abd12",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f19b526-97de-4fcf-8284-65aca00443dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfa3d28-927c-49f5-8ece-756ca792524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAM(torch.optim.Optimizer):\n",
    "    def __init__(self, params, base_optimizer, rho=0.05, adaptive=False, **kwargs):\n",
    "        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n",
    "\n",
    "        defaults = dict(rho=rho, adaptive=adaptive, **kwargs)\n",
    "        super(SAM, self).__init__(params, defaults)\n",
    "\n",
    "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
    "        self.param_groups = self.base_optimizer.param_groups\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def first_step(self, zero_grad=False):\n",
    "        grad_norm = self._grad_norm()\n",
    "        for group in self.param_groups:\n",
    "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                self.state[p][\"old_p\"] = p.data.clone()\n",
    "                e_w = (torch.pow(p, 2) if group[\"adaptive\"] else 1.0) * p.grad * scale.to(p)\n",
    "                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def second_step(self, scaler=None, zero_grad=False):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                p.data = self.state[p][\"old_p\"]  # get back to \"w\" from \"w + e(w)\"\n",
    "\n",
    "        if scaler:\n",
    "            scaler.step(self.base_optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n",
    "        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass\n",
    "\n",
    "        self.first_step(zero_grad=True)\n",
    "        closure()\n",
    "        self.second_step()\n",
    "\n",
    "    def _grad_norm(self):\n",
    "        shared_device = self.param_groups[0][\"params\"][0].device  # put everything on the same device, in case of model parallelism\n",
    "        norm = torch.norm(\n",
    "                    torch.stack([\n",
    "                        ((torch.abs(p) if group[\"adaptive\"] else 1.0) * p.grad).norm(p=2).to(shared_device)\n",
    "                        for group in self.param_groups for p in group[\"params\"]\n",
    "                        if p.grad is not None\n",
    "                    ]),\n",
    "                    p=2\n",
    "               )\n",
    "        return norm\n",
    "    \n",
    "    def load_state_dict(self, state_dict):\n",
    "        super().load_state_dict(state_dict)\n",
    "        self.base_optimizer.param_groups = self.param_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3dc3bb-0978-43f5-bd60-dcac7b87c0aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CosineAnnealingWarmUpRestarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d4a1c3-7204-474c-ba18-ee8f92c9ca39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CosineAnnealingWarmUpRestarts(torch.optim.lr_scheduler._LRScheduler):\n",
    "    def __init__(self, optimizer, T_0, T_mult=1, eta_max=0.1, T_up=0, gamma=1., last_epoch=-1):\n",
    "        if T_0 <= 0 or not isinstance(T_0, int):\n",
    "            raise ValueError(\"Expected positive integer T_0, but got {}\".format(T_0))\n",
    "        if T_mult < 1 or not isinstance(T_mult, int):\n",
    "            raise ValueError(\"Expected integer T_mult >= 1, but got {}\".format(T_mult))\n",
    "        if T_up < 0 or not isinstance(T_up, int):\n",
    "            raise ValueError(\"Expected positive integer T_up, but got {}\".format(T_up))\n",
    "        self.T_0 = T_0\n",
    "        self.T_mult = T_mult\n",
    "        self.base_eta_max = eta_max\n",
    "        self.eta_max = eta_max\n",
    "        self.T_up = T_up\n",
    "        self.T_i = T_0\n",
    "        self.gamma = gamma\n",
    "        self.cycle = 0\n",
    "        self.T_cur = last_epoch\n",
    "        super(CosineAnnealingWarmUpRestarts, self).__init__(optimizer, last_epoch)\n",
    "    \n",
    "    def get_lr(self):\n",
    "        if self.T_cur == -1:\n",
    "            return self.base_lrs\n",
    "        elif self.T_cur < self.T_up:\n",
    "            return [(self.eta_max - base_lr)*self.T_cur / self.T_up + base_lr for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr + (self.eta_max - base_lr) * (1 + math.cos(math.pi * (self.T_cur-self.T_up) / (self.T_i - self.T_up))) / 2\n",
    "                    for base_lr in self.base_lrs]\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "            self.T_cur = self.T_cur + 1\n",
    "            if self.T_cur >= self.T_i:\n",
    "                self.cycle += 1\n",
    "                self.T_cur = self.T_cur - self.T_i\n",
    "                self.T_i = (self.T_i - self.T_up) * self.T_mult + self.T_up\n",
    "        else:\n",
    "            if epoch >= self.T_0:\n",
    "                if self.T_mult == 1:\n",
    "                    self.T_cur = epoch % self.T_0\n",
    "                    self.cycle = epoch // self.T_0\n",
    "                else:\n",
    "                    n = int(math.log((epoch / self.T_0 * (self.T_mult - 1) + 1), self.T_mult))\n",
    "                    self.cycle = n\n",
    "                    self.T_cur = epoch - self.T_0 * (self.T_mult ** n - 1) / (self.T_mult - 1)\n",
    "                    self.T_i = self.T_0 * self.T_mult ** (n)\n",
    "            else:\n",
    "                self.T_i = self.T_0\n",
    "                self.T_cur = epoch\n",
    "                \n",
    "        self.eta_max = self.base_eta_max * (self.gamma**self.cycle)\n",
    "        self.last_epoch = math.floor(epoch)\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr\n",
    "        print(\"learning rate:\", lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e2b4ee-78e5-4694-9739-55ec426841ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cf4d1a-5d1a-47bb-8324-75ccc9a34d29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score\n",
    "\n",
    "def disable_running_stats(model):\n",
    "    def _disable(module):\n",
    "        if isinstance(module, nn.BatchNorm2d):\n",
    "            module.backup_momentum = module.momentum\n",
    "            module.momentum = 0\n",
    "\n",
    "    model.apply(_disable)\n",
    "\n",
    "def enable_running_stats(model):\n",
    "    def _enable(module):\n",
    "        if isinstance(module, nn.BatchNorm2d) and hasattr(module, \"backup_momentum\"):\n",
    "            module.momentum = module.backup_momentum\n",
    "\n",
    "    model.apply(_enable)\n",
    "    \n",
    "def calc_loss(z, j):\n",
    "    squared_error = torch.sum(z**2, (1, 2, 3)) / 2\n",
    "    jacob = torch.sum(j, (1, 2, 3))\n",
    "    return squared_error - jacob\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LR/2 * 0.01\n",
    "    if epoch >= int(EPOCHS*0.9):\n",
    "        lr = LR/2 * 0.000001\n",
    "    elif epoch >= int(EPOCHS*0.8):\n",
    "        lr = LR/2 * 0.0001\n",
    "    print(\"learing rate:\", lr)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "        \n",
    "def cdb_adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    if epoch >= int(EPOCHS*0.9):\n",
    "        lr = LR/3 * 0.0001\n",
    "    elif epoch >= int(EPOCHS*0.8):\n",
    "        lr = LR/3 * 0.01\n",
    "    print(\"learing rate:\", lr)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "        \n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(cr, pred, y_a, y_b, lam):\n",
    "    if cr == \"sc\":\n",
    "        return lam * smooth_crossentropy(pred, y_a).mean() + (1 - lam) * smooth_crossentropy(pred, y_b).mean()\n",
    "    elif cr == \"ib\":\n",
    "        return lam * criterion_ib(pred, y_a) + (1 - lam) * criterion_ib(pred, y_b)\n",
    "    elif cr == \"cr\":\n",
    "        return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "    elif cr == \"bs\":\n",
    "        return lam * balanced_softmax_loss(pred, y_a) + (1 - lam) * balanced_softmax_loss(pred, y_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb3a667-f7b6-4686-b0ee-98e1c598485f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1e6d91-f141-484e-8e6a-baf78791ba4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_FILE)\n",
    "\n",
    "LABEL = [line for line in train_df[\"label\"]]\n",
    "LABEL, SAMPLES_PER_CLS = np.unique(LABEL, return_counts=True)\n",
    "LABEL_ENCODER = {k: i for i, k in enumerate(LABEL)}\n",
    "LABEL_DECODER = {v: k for k, v in LABEL_ENCODER.items()}\n",
    "\n",
    "# ---------------  SAMPLER ------------------\n",
    "# per_cls_weights = 1.0 / np.array(SAMPLES_PER_CLS)\n",
    "# per_cls_weights = per_cls_weights / np.sum(per_cls_weights) * len(SAMPLES_PER_CLS)\n",
    "# per_cls_weights = torch.DoubleTensor(per_cls_weights)\n",
    "# sampler = WeightedRandomSampler(per_cls_weights, len(per_cls_weights))\n",
    "\n",
    "# sampler_dic = {\n",
    "#     'sampler': get_sampler(),\n",
    "#     'params': {'num_samples_cls': 4}\n",
    "# }\n",
    "# ---------------  SAMPLER ------------------\n",
    "train_dataset = CustomDataset(df=train_df, mode=\"train\")\n",
    "train_loader = DataLoader(\n",
    "                    train_dataset,\n",
    "                    batch_size=BATCH,\n",
    "                    shuffle=True,\n",
    "                    pin_memory=True,\n",
    "                    num_workers=NUM_WORKERS,\n",
    "                    # sampler=sampler_dic['sampler'](train_dataset, **sampler_dic['params']),\n",
    "                    # batch_sampler=sampler_dic,\n",
    "                    # drop_last=True,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b4800d-e84d-4ef2-8099-43da158a1ef0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb98893a-f16f-485a-bb89-b9f1e9f07871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize(image):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "\n",
    "for batch in train_loader:\n",
    "    for i in batch[0]:\n",
    "        visualize(i.moveaxis(0, -1))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa64565-5576-4709-a669-e06ed4a4220e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d35476-0b51-4f52-bd93-721e9dc56af0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, mode=\"train\"):\n",
    "        super(Network, self).__init__()\n",
    "        self.mode = mode\n",
    "        if self.mode == \"train\":\n",
    "            self.drop_out_rate = DROP_OUT_RATE\n",
    "            self.drop_path_rate = DROP_PATH_RATE\n",
    "        elif self.mode == \"test\":\n",
    "            self.drop_out_rate = 0\n",
    "            self.drop_path_rate = 0\n",
    "            \n",
    "        self.backbone = timm.create_model(MODEL_NAME, pretrained=True, num_classes=NUM_CLASS, drop_rate=self.drop_out_rate)#, drop_path_rate=self.drop_path_rate)\n",
    "        # self.linears = nn.ModuleList([NormedLinear(2432, NUM_CLASS) for _ in range(2)])\n",
    "        # self.base_expert = nn.Linear(self.backbone.conv_head.out_channels, NUM_CLASS)\n",
    "        # self.balance_expert = nn.Linear(self.backbone.conv_head.out_channels, NUM_CLASS)\n",
    "        # self.inverse_expert = nn.Linear(self.backbone.conv_head.out_channels, NUM_CLASS)\n",
    "        # self.RSG = RSG(n_center = 15, feature_maps_shape = [32, 16, 16], num_classes=num_classes, contrastive_module_dim = 256, head_class_lists = self.head_lists, transfer_strength = transfer_strength, epoch_thresh = epoch_thresh)\n",
    "        # self.ml_decoder = MLDecoder(NUM_CLASS, initial_num_features=self.backbone.conv_head.out_channels)\n",
    "        # self.classifier = nn.Linear(self.backbone.conv_head.out_channels, NUM_CLASS)\n",
    "        # self.backbone.global_pool = nn.Identity()\n",
    "        # del self.backbone.head\n",
    "        # self.backbone.head = MLDecoder(NUM_CLASS, initial_num_features=self.backbone.norm.normalized_shape[0])\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.mode == \"train\":\n",
    "            x = self.backbone(x)\n",
    "            # feats = F.avg_pool2d(x, x.size()[3])\n",
    "            # x = self.ml_decoder(x)\n",
    "            # # feats = feats.view(feats.size(0), -1)\n",
    "            return x#, torch.sum(torch.abs(feats), 1).reshape(-1, 1)\n",
    "            # out1 = out.view(out.size(0), -1)\n",
    "            # x = self.ml_decoder(x)\n",
    "            # return {\n",
    "            #     \"base\": self.linears[0](x),\n",
    "            #     # \"balance\": self.linears[1](x),\n",
    "            #     \"inverse\": self.linears[1](x)\n",
    "            # }\n",
    "        \n",
    "        elif self.mode == \"test\":\n",
    "            x = self.backbone(x)\n",
    "            # x = self.ml_decoder(x)\n",
    "            return x\n",
    "            # outputs = []\n",
    "            # for i in range(2):\n",
    "            #     outputs.append(self.linears[i](x))\n",
    "            # outs = []\n",
    "            # for o in outputs:\n",
    "            #     outs.append(o)\n",
    "            # outputs = torch.stack(outs, dim=1).mean(dim=1)\n",
    "            # return outputs\n",
    "        \n",
    "     \n",
    "        \n",
    "# class NormedLinear(nn.Module):\n",
    "\n",
    "#     def __init__(self, in_features, out_features):\n",
    "#         super(NormedLinear, self).__init__()\n",
    "#         self.weight = Parameter(torch.Tensor(in_features, out_features))\n",
    "#         self.weight.data.uniform_(-1, 1).renorm_(2, 1, 1e-5).mul_(1e5)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         out = F.normalize(x, dim=1).mm(F.normalize(self.weight, dim=0))\n",
    "#         return out\n",
    "    \n",
    "\n",
    "class NormedLinear(nn.Linear):\n",
    "    \"\"\"Normalized Linear Layer.\n",
    "    Args:\n",
    "        tempeature (float, optional): Tempeature term. Default to 20.\n",
    "        power (int, optional): Power term. Default to 1.0.\n",
    "        eps (float, optional): The minimal value of divisor to\n",
    "             keep numerical stability. Default to 1e-6.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, tempearture=20, power=1.0, eps=1e-6, **kwargs):\n",
    "        super(NormedLinear, self).__init__(*args, **kwargs)\n",
    "        self.tempearture = tempearture\n",
    "        self.power = power\n",
    "        self.eps = eps\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        nn.init.normal_(self.weight, mean=0, std=0.01)\n",
    "        if self.bias is not None:\n",
    "            nn.init.constant_(self.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        weight_ = self.weight / (\n",
    "            self.weight.norm(dim=1, keepdim=True).pow(self.power) + self.eps)\n",
    "        x_ = x / (x.norm(dim=1, keepdim=True).pow(self.power) + self.eps)\n",
    "        x_ = x_ * self.tempearture\n",
    "\n",
    "        return F.linear(x_, weight_, self.bias)\n",
    "    \n",
    "    \n",
    "# model = Network()\n",
    "# # print(model(torch.randn(1, 3, 224, 224)))\n",
    "# print(model)\n",
    "# model.to(DEVICE)\n",
    "# print(f\"model {MODEL_NAME} create!\")\n",
    "\n",
    "# model\n",
    "# from pprint import pprint\n",
    "# model_names = timm.list_models(\"*tres*\", pretrained=False)\n",
    "# pprint(model_names)\n",
    "# z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecfe24a-ac75-4037-b3ea-27c4a873c34a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dyhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad7005d-fc0a-44df-aa8f-f8baae4c22d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # # from pprint import pprint\n",
    "# # # model_names = timm.list_models(\"*swin*\", pretrained=True)\n",
    "# # # pprint(model_names)\n",
    "# from collections import OrderedDict\n",
    "\n",
    "# class Network(nn.Module):\n",
    "#     def __init__(self, mode=\"train\"):\n",
    "#         super(Network, self).__init__()\n",
    "#         out_featrues = 256\n",
    "#         self.mode = mode\n",
    "#         # self.backbone = timm.create_model(MODEL_NAME, pretrained=True, num_classes=NUM_CLASS, drop_path_rate=DROP_PATH_RATIO)#num_classes=0, global_pool=\"\")#, drop_path_rate=0.2)\n",
    "#         self.backbone = timm.create_model(MODEL_NAME, pretrained=True, features_only=True, drop_path_rate=DROP_PATH_RATIO)\n",
    "#         self.fpn = FeaturePyramidNetwork([48, 64, 160, 256], out_featrues)\n",
    "#         self.concat_fpn = concat_feature_maps()\n",
    "#         # self.scale_layer = Scale_Aware_Layer\n",
    "#         # self.spatial_layer = Spatial_Aware_Layer\n",
    "#         # self.task_layer = Task_Aware_Layer\n",
    "#         # L: 4 S: 441 C: 256\n",
    "#         self.dyhead = DyHead(num_blocks=6, L=4, S=784, C=256)\n",
    "#         self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "#         self.classifier = nn.Linear(256, NUM_CLASS)\n",
    "#         # self.ml_decoder = MLDecoder(NUM_CLASS, initial_num_features=1280)\n",
    "#         # for _, param in self.backbone.named_parameters():\n",
    "#         #     param.requires_grad = False\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.backbone(x)[1:]\n",
    "\n",
    "#         x_dic = OrderedDict()\n",
    "#         for i in range(len(x)):\n",
    "#             x_dic[f\"feat{i}\"] = x[i]\n",
    "\n",
    "#         x = self.fpn(x_dic)\n",
    "#         x = self.concat_fpn(x)\n",
    "#         x = self.dyhead(x)\n",
    "        \n",
    "#         F_tensor = x.permute(0, 3, 1, 2)\n",
    "#         kernel_size = F_tensor.shape[2:] # Getting HxW of F\n",
    "#         gap_output = F.avg_pool2d(F_tensor, kernel_size)\n",
    "\n",
    "#         # Flattening gap_output from (batch_size, C, 1, 1) to (batch_size, C)\n",
    "#         gap_output = gap_output.flatten(start_dim=1)\n",
    "        \n",
    "#         # x = x.transpose(dim0=1, dim1=-1)\n",
    "#         # x = self.avg_pool(x)\n",
    "#         # x = x.flatten(1)\n",
    "#         x = self.classifier(gap_output)\n",
    "#         return x\n",
    "#         # feats = []\n",
    "#         # for k, v in x.items():\n",
    "#         #     v = self.avg_pool(v)\n",
    "#         #     feats.append(v.flatten(1))\n",
    "#         # feats = torch.cat(feats, 1)\n",
    "        \n",
    "#         # x = self.classifier(x)\n",
    "#         # feats = self.backbone(x)\n",
    "#         # x = self.classifier(feats)\n",
    "#         # x = self.ml_decoder(x)\n",
    "#         # return x\n",
    "#         # if self.mode == \"train\":\n",
    "#         #     return x, torch.sum(torch.abs(feats), 1).reshape(-1, 1)\n",
    "#         # else:\n",
    "\n",
    "        \n",
    "# class concat_feature_maps(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(concat_feature_maps, self).__init__()\n",
    "\n",
    "#     def forward(self, fpn_output):\n",
    "#         # Calculating median height to upsample or desample each fpn levels\n",
    "#         heights = []\n",
    "#         level_tensors = []\n",
    "#         for key, values in fpn_output.items():\n",
    "#             heights.append(values.shape[2])\n",
    "#             level_tensors.append(values)\n",
    "#         median_height = int(np.median(heights))\n",
    "\n",
    "#         # Upsample and Desampling tensors to median height and width\n",
    "#         for i in range(len(level_tensors)):\n",
    "#             level = level_tensors[i]\n",
    "#             # If level height is greater than median, then downsample with interpolate\n",
    "#             if level.shape[2] > median_height:\n",
    "#                 level = F.interpolate(input=level, size=(median_height, median_height),mode='nearest')\n",
    "#             # If level height is less than median, then upsample\n",
    "#             else:\n",
    "#                 level = F.interpolate(input=level, size=(median_height, median_height), mode='nearest')\n",
    "#             level_tensors[i] = level\n",
    "        \n",
    "#         # Concating all levels with dimensions (batch_size, levels, C, H, W)\n",
    "#         concat_levels = torch.stack(level_tensors, dim=1)\n",
    "\n",
    "#         # Reshaping tensor from (batch_size, levels, C, H, W) to (batch_size, levels, HxW=S, C)\n",
    "#         concat_levels = concat_levels.flatten(start_dim=3).transpose(dim0=2, dim1=3)\n",
    "#         return concat_levels\n",
    "\n",
    "\n",
    "# class Scale_Aware_Layer(nn.Module):\n",
    "#     # Constructor\n",
    "#     def __init__(self, s_size):\n",
    "#         super(Scale_Aware_Layer, self).__init__()\n",
    "\n",
    "#         # Average Pooling\n",
    "#         self.avg_layer = nn.AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "#         #1x1 Conv layer\n",
    "#         self.conv = nn.Conv2d(in_channels=s_size, out_channels=1, kernel_size=1)\n",
    "\n",
    "#         # Hard Sigmoid\n",
    "#         self.hard_sigmoid = nn.Hardsigmoid()\n",
    "\n",
    "#         # ReLU function\n",
    "#         self.relu = nn.ReLU()\n",
    "\n",
    "#     def forward(self, F):\n",
    "\n",
    "#         # Transposing input from (batch_size, L, S, C) to (batch_size, S, L, C) so we can use convolutional layer over the level dimension L\n",
    "#         x = F.transpose(dim0=2, dim1=1)\n",
    "\n",
    "#         # Passing tensor through avg pool layer\n",
    "#         x = self.avg_layer(x)\n",
    "\n",
    "#         # Passing tensor through Conv layer\n",
    "#         x = self.conv(x)\n",
    "        \n",
    "#         # Reshaping Tensor from (batch_size, 1, L, C) to (batch_size, L, 1, C) to then be multiplied to F\n",
    "#         x = x.transpose(dim0=1, dim1=2)\n",
    "\n",
    "#         # Passing conv output to relu\n",
    "#         x = self.relu(x)\n",
    "\n",
    "#         # Passing tensor to hard sigmoid function\n",
    "#         pi_L = self.hard_sigmoid(x)\n",
    "\n",
    "#         # pi_L: (batch_size, L, 1, C)\n",
    "#         # F: (batch_size, L, S, C)\n",
    "#         return pi_L * F\n",
    "\n",
    "    \n",
    "# class Spatial_Aware_Layer(nn.Module):\n",
    "#     # Constructor\n",
    "#     def __init__(self, L_size, kernel_height=3, kernel_width=3, padding=1, stride=1, dilation=1, groups=1):\n",
    "#         super(Spatial_Aware_Layer, self).__init__()\n",
    "\n",
    "#         self.in_channels = L_size\n",
    "#         self.out_channels = L_size\n",
    "\n",
    "#         self.kernel_size = (kernel_height, kernel_width)\n",
    "#         self.padding = padding\n",
    "#         self.stride = stride\n",
    "#         self.dilation = dilation\n",
    "#         self.K = kernel_height * kernel_width\n",
    "#         self.groups = groups\n",
    "\n",
    "#         # 3x3 Convolution with 3K out_channel output as described in Deform Conv2 paper\n",
    "#         self.offset_and_mask_conv = nn.Conv2d(in_channels=self.in_channels,\n",
    "#                                               out_channels=3*self.K, #3K depth\n",
    "#                                               kernel_size=self.kernel_size,\n",
    "#                                               stride=self.stride,\n",
    "#                                               padding=self.padding,\n",
    "#                                               dilation=dilation)\n",
    "        \n",
    "#         self.deform_conv = DeformConv2d(in_channels=self.in_channels,\n",
    "#                                         out_channels=self.out_channels,\n",
    "#                                         kernel_size=self.kernel_size,\n",
    "#                                         stride=self.stride,\n",
    "#                                         padding=self.padding,\n",
    "#                                         dilation=self.dilation,\n",
    "#                                         groups=self.groups)\n",
    "#     def forward(self, F):\n",
    "#         # Generating offesets and masks (or modulators) for convolution operation\n",
    "#         offsets_and_masks = self.offset_and_mask_conv(F)\n",
    "\n",
    "#         # Separating offsets and masks as described in Deform Conv v2 paper\n",
    "#         offset = offsets_and_masks[:, :2*self.K, :, :] # First 2K channels \n",
    "#         mask = torch.sigmoid(offsets_and_masks[:, 2*self.K:, : , :]) # Last 1K channels and passing it through sigmoid\n",
    "\n",
    "#         # Passing offsets, masks, and F into deform conv layer\n",
    "#         spacial_output = self.deform_conv(F, offset, mask)\n",
    "#         return spacial_output\n",
    "\n",
    "    \n",
    "# # DyReLUA technique from Dynamic ReLU paper\n",
    "# class DyReLUA(nn.Module):\n",
    "#     def __init__(self, channels, reduction=8, k=2, lambdas=None, init_values=None):\n",
    "#         super(DyReLUA, self).__init__()\n",
    "\n",
    "#         self.fc1 = nn.Linear(channels, channels // reduction)\n",
    "#         self.fc2 = nn.Linear(channels//reduction, 2*k)\n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "#         # Defining lambdas in form of [La1, La2, Lb1, Lb2]\n",
    "#         if lambdas is not None:\n",
    "#             self.lambdas = lambdas\n",
    "#         else:\n",
    "#             # Default lambdas from DyReLU paper\n",
    "#             self.lambdas = torch.cuda.HalfTensor([1.0, 1.0, 0.5, 0.5])\n",
    "\n",
    "#         # Defining Initializing values in form of [alpha1, alpha2, Beta1, Beta2]\n",
    "#         if lambdas is not None:\n",
    "#             self.init_values = init_values\n",
    "#         else:\n",
    "#             # Default initializing values of DyReLU paper\n",
    "#             self.init_values = torch.cuda.HalfTensor([1.0, 0.0, 0.0, 0.0])\n",
    "\n",
    "#     def forward(self, F_tensor):\n",
    "\n",
    "#         # Global Averaging F\n",
    "#         kernel_size = F_tensor.shape[2:] # Getting HxW of F\n",
    "#         gap_output = F.avg_pool2d(F_tensor, kernel_size)\n",
    "\n",
    "#         # Flattening gap_output from (batch_size, C, 1, 1) to (batch_size, C)\n",
    "#         gap_output = gap_output.flatten(start_dim=1)\n",
    "\n",
    "#         # Passing Global Average output through Fully-Connected Layers\n",
    "#         x = self.relu(self.fc1(gap_output))\n",
    "#         x = self.fc2(x)\n",
    "        \n",
    "#         # Normalization between (-1, 1)\n",
    "#         residuals = 2 * self.sigmoid(x) - 1\n",
    "\n",
    "#         # Getting values of theta, and separating alphas and betas\n",
    "#         theta = self.init_values + self.lambdas * residuals # Contains[alpha1(x), alpha2(x), Beta1(x), Beta2(x)]\n",
    "#         alphas = theta[0, :2]\n",
    "#         betas = theta[0, 2:]\n",
    "\n",
    "#         # Performing maximum on both piecewise functions\n",
    "#         output = torch.maximum((alphas[0] * F_tensor + betas[0]), (alphas[1] * F_tensor + betas[1]))\n",
    "\n",
    "#         return output\n",
    "\n",
    "    \n",
    "# class Task_Aware_Layer(nn.Module):\n",
    "#     # Defining constructor\n",
    "#     def __init__(self, num_channels):\n",
    "#         super(Task_Aware_Layer, self).__init__()\n",
    "\n",
    "#         # DyReLUA relu\n",
    "#         self.dynamic_relu = DyReLUA(num_channels)\n",
    "    \n",
    "#     def forward(self, F_tensor):\n",
    "#         # Permutating F from (batch_size, L, S, C) to (batch_size, C, L, S) so we can reduce the dimensions over LxS\n",
    "#         F_tensor = F_tensor.permute(0, 3, 1, 2)\n",
    "#         output = self.dynamic_relu(F_tensor)\n",
    "        \n",
    "#         # Reversing the permutation\n",
    "#         output = output.permute(0, 2, 3, 1)\n",
    "\n",
    "#         return output\n",
    "\n",
    "\n",
    "# class DyHead_Block(nn.Module):\n",
    "#     def __init__(self, L, S, C):\n",
    "#         super(DyHead_Block, self).__init__()\n",
    "#         # Saving all dimension sizes of F\n",
    "#         self.L_size = L\n",
    "#         self.S_size = S\n",
    "#         self.C_size = C\n",
    "\n",
    "#         # Inititalizing all attention layers\n",
    "#         self.scale_attention = Scale_Aware_Layer(s_size=self.S_size)\n",
    "#         self.spatial_attention = Spatial_Aware_Layer(L_size=self.L_size)\n",
    "#         self.task_attention = Task_Aware_Layer(num_channels=self.C_size)\n",
    "\n",
    "#     def forward(self, F_tensor):\n",
    "#         scale_output = self.scale_attention(F_tensor)\n",
    "#         spacial_output = self.spatial_attention(scale_output)\n",
    "#         task_output = self.task_attention(spacial_output)\n",
    "\n",
    "#         return task_output\n",
    "\n",
    "# def DyHead(num_blocks, L, S, C):\n",
    "#     blocks = [('Block_{}'.format(i+1),DyHead_Block(L, S, C)) for i in range(num_blocks)]\n",
    "\n",
    "#     return nn.Sequential(OrderedDict(blocks))\n",
    "\n",
    "\n",
    "# model = Network()\n",
    "# model.to(DEVICE)\n",
    "# print(f\"model {MODEL_NAME} create!\")\n",
    "# # for i, (k, param) in enumerate(model.named_parameters()):\n",
    "# #     if i < 644:\n",
    "# #         param.requires_grad = False\n",
    "# #     print(i, k, param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796231d7-4f63-416f-b0db-c7a3287cc28f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ML-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a25a0b2-5771-4ed2-81fe-23afefa73ef1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_ml_decoder_head(model, num_classes=-1, num_of_groups=-1, decoder_embedding=768, zsl=0):\n",
    "    if num_classes == -1:\n",
    "        num_classes = model.num_classes\n",
    "    num_features = model.num_features\n",
    "    if hasattr(model, 'global_pool') and hasattr(model, 'fc'):  # resnet50\n",
    "        model.global_pool = nn.Identity()\n",
    "        del model.fc\n",
    "        model.fc = MLDecoder(num_classes=num_classes, initial_num_features=num_features, num_of_groups=num_of_groups,\n",
    "                             decoder_embedding=decoder_embedding, zsl=zsl)\n",
    "    elif hasattr(model, 'head'):  # tresnet\n",
    "        if hasattr(model, 'global_pool'):\n",
    "            model.global_pool = nn.Identity()\n",
    "        del model.head\n",
    "        model.head = MLDecoder(num_classes=num_classes, initial_num_features=num_features, num_of_groups=num_of_groups,\n",
    "                               decoder_embedding=decoder_embedding, zsl=zsl)\n",
    "    else:\n",
    "        print(\"model is not suited for ml-decoder\")\n",
    "        exit(-1)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "class TransformerDecoderLayerOptimal(nn.Module):\n",
    "    def __init__(self, d_model, nhead=8, dim_feedforward=2048, dropout=0.1, activation=\"relu\",\n",
    "                 layer_norm_eps=1e-5) -> None:\n",
    "        super(TransformerDecoderLayerOptimal, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(d_model, eps=layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "\n",
    "        self.multihead_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "\n",
    "        # Implementation of Feedforward model\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "\n",
    "        self.norm2 = nn.LayerNorm(d_model, eps=layer_norm_eps)\n",
    "        self.norm3 = nn.LayerNorm(d_model, eps=layer_norm_eps)\n",
    "\n",
    "        self.activation = _get_activation_fn(activation)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        if 'activation' not in state:\n",
    "            state['activation'] = torch.nn.functional.relu\n",
    "        super(TransformerDecoderLayerOptimal, self).__setstate__(state)\n",
    "\n",
    "    def forward(self, tgt, memory, tgt_mask = None,\n",
    "                memory_mask = None,\n",
    "                tgt_key_padding_mask = None,\n",
    "                memory_key_padding_mask = None):\n",
    "        tgt = tgt + self.dropout1(tgt)\n",
    "        tgt = self.norm1(tgt)\n",
    "        tgt2 = self.multihead_attn(tgt, memory, memory)[0]\n",
    "        tgt = tgt + self.dropout2(tgt2)\n",
    "        tgt = self.norm2(tgt)\n",
    "        tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt))))\n",
    "        tgt = tgt + self.dropout3(tgt2)\n",
    "        tgt = self.norm3(tgt)\n",
    "        return tgt\n",
    "\n",
    "class GroupFC(object):\n",
    "    def __init__(self, embed_len_decoder: int):\n",
    "        self.embed_len_decoder = embed_len_decoder\n",
    "\n",
    "    def __call__(self, h, duplicate_pooling, out_extrap):\n",
    "        for i in range(h.shape[1]):\n",
    "            h_i = h[:, i, :]\n",
    "            if len(duplicate_pooling.shape)==3:\n",
    "                w_i = duplicate_pooling[i, :, :]\n",
    "            else:\n",
    "                w_i = duplicate_pooling\n",
    "            out_extrap[:, i, :] = torch.matmul(h_i, w_i)\n",
    "\n",
    "\n",
    "class MLDecoder(nn.Module):\n",
    "    def __init__(self, num_classes, num_of_groups=-1, decoder_embedding=768,\n",
    "                 initial_num_features=2048, zsl=0):\n",
    "        super(MLDecoder, self).__init__()\n",
    "        embed_len_decoder = 100 if num_of_groups < 0 else num_of_groups\n",
    "        if embed_len_decoder > num_classes:\n",
    "            embed_len_decoder = num_classes\n",
    "\n",
    "        # switching to 768 initial embeddings\n",
    "        decoder_embedding = 768 if decoder_embedding < 0 else decoder_embedding\n",
    "        embed_standart = nn.Linear(initial_num_features, decoder_embedding)\n",
    "\n",
    "        # non-learnable queries\n",
    "        if not zsl:\n",
    "            query_embed = nn.Embedding(embed_len_decoder, decoder_embedding)\n",
    "            query_embed.requires_grad_(False)\n",
    "        else:\n",
    "            query_embed = None\n",
    "\n",
    "        # decoder\n",
    "        decoder_dropout = 0.1\n",
    "        num_layers_decoder = 1\n",
    "        dim_feedforward = 2048\n",
    "        layer_decode = TransformerDecoderLayerOptimal(d_model=decoder_embedding,\n",
    "                                                      dim_feedforward=dim_feedforward, dropout=decoder_dropout)\n",
    "        self.decoder = nn.TransformerDecoder(layer_decode, num_layers=num_layers_decoder)\n",
    "        self.decoder.embed_standart = embed_standart\n",
    "        self.decoder.query_embed = query_embed\n",
    "        self.zsl = zsl\n",
    "\n",
    "        if self.zsl:\n",
    "            if decoder_embedding != 300:\n",
    "                self.wordvec_proj = nn.Linear(300, decoder_embedding)\n",
    "            else:\n",
    "                self.wordvec_proj = nn.Identity()\n",
    "            self.decoder.duplicate_pooling = torch.nn.Parameter(torch.Tensor(decoder_embedding, 1))\n",
    "            self.decoder.duplicate_pooling_bias = torch.nn.Parameter(torch.Tensor(1))\n",
    "            self.decoder.duplicate_factor = 1\n",
    "        else:\n",
    "            # group fully-connected\n",
    "            self.decoder.num_classes = num_classes\n",
    "            self.decoder.duplicate_factor = int(num_classes / embed_len_decoder + 0.999)\n",
    "            self.decoder.duplicate_pooling = torch.nn.Parameter(\n",
    "                torch.Tensor(embed_len_decoder, decoder_embedding, self.decoder.duplicate_factor))\n",
    "            self.decoder.duplicate_pooling_bias = torch.nn.Parameter(torch.Tensor(num_classes))\n",
    "        torch.nn.init.xavier_normal_(self.decoder.duplicate_pooling)\n",
    "        torch.nn.init.constant_(self.decoder.duplicate_pooling_bias, 0)\n",
    "        self.decoder.group_fc = GroupFC(embed_len_decoder)\n",
    "        self.train_wordvecs = None\n",
    "        self.test_wordvecs = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 4:  # [bs,2048, 7,7]\n",
    "            embedding_spatial = x.flatten(2).transpose(1, 2)\n",
    "        else:  # [bs, 197,468]\n",
    "            embedding_spatial = x\n",
    "        embedding_spatial_786 = self.decoder.embed_standart(embedding_spatial)\n",
    "        embedding_spatial_786 = torch.nn.functional.relu(embedding_spatial_786, inplace=True)\n",
    "\n",
    "        bs = embedding_spatial_786.shape[0]\n",
    "        if self.zsl:\n",
    "            query_embed = torch.nn.functional.relu(self.wordvec_proj(self.decoder.query_embed))\n",
    "        else:\n",
    "            query_embed = self.decoder.query_embed.weight\n",
    "        # tgt = query_embed.unsqueeze(1).repeat(1, bs, 1)\n",
    "        tgt = query_embed.unsqueeze(1).expand(-1, bs, -1)  # no allocation of memory with expand\n",
    "        h = self.decoder(tgt, embedding_spatial_786.transpose(0, 1))  # [embed_len_decoder, batch, 768]\n",
    "        h = h.transpose(0, 1)\n",
    "\n",
    "        out_extrap = torch.zeros(h.shape[0], h.shape[1], self.decoder.duplicate_factor, device=h.device, dtype=h.dtype)\n",
    "        self.decoder.group_fc(h, self.decoder.duplicate_pooling, out_extrap)\n",
    "        if not self.zsl:\n",
    "            h_out = out_extrap.flatten(1)[:, :self.decoder.num_classes]\n",
    "        else:\n",
    "            h_out = out_extrap.flatten(1)\n",
    "        h_out += self.decoder.duplicate_pooling_bias\n",
    "        logits = h_out\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407f487c-71b8-484a-9fd7-ba7d0143506f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Optimizer & Criterion & Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e1ed0d-cc51-4872-a67e-6bbf951f10ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Network()\n",
    "model.to(DEVICE)\n",
    "\n",
    "\n",
    "# for i, (k, param) in enumerate(model.named_parameters()):\n",
    "#     if i < 363:\n",
    "#         param.requires_grad = False\n",
    "#     print(i, k, param.requires_grad)\n",
    "\n",
    "print(f\"model {MODEL_NAME} create!\")\n",
    "\n",
    "# ------------ SAM ------------------\n",
    "# base_optimizer = torch.optim.SGD\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
    "# optimizer = SAM(model.parameters(), base_optimizer, lr=LR, rho=2.0, adaptive=True, weight_decay=WD)#, nesterov=True, momentum=MOMENTUM)\n",
    "# scheduler = CosineAnnealingWarmUpRestarts(optimizer.base_optimizer, T_0=50, T_mult=1, eta_max=LR,  T_up=0, gamma=0.5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, verbose=True)\n",
    "# ------------ SAM ------------------\n",
    "\n",
    "# ------------ IB-Loss ------------------\n",
    "# per_cls_weights = 1.0 / np.array(SAMPLES_PER_CLS)\n",
    "# per_cls_weights = per_cls_weights / np.sum(per_cls_weights) * len(SAMPLES_PER_CLS)\n",
    "# per_cls_weights = torch.FloatTensor(per_cls_weights).cuda()\n",
    "# criterion_ib = IB_FocalLoss(weight=per_cls_weights, alpha=1000, gamma=1).cuda()\n",
    "# criterion_ib = IBLoss(weight=per_cls_weights, alpha=1000).cuda()\n",
    "# ------------ IB-Loss ------------------\n",
    "# criterion = FocalCosineLoss().cuda()\n",
    "# criterion = nn.CrossEntropyLoss().cuda()\n",
    "# criterion = SmoothCrossentropy().cuda()\n",
    "# criterion = BalancedSoftmax().cuda()\n",
    "# criterion = FocalLoss(alpha=0.25, gamma=2, label_smoothing=0.1).cuda()\n",
    "# criterion = CDB_loss(class_difficulty = np.ones(NUM_CLASS)).cuda()\n",
    "\n",
    "# optimizer = optim.Lamb(\n",
    "#     model.parameters(),\n",
    "#     lr= LR,\n",
    "#     betas=(0.9, 0.999),\n",
    "#     eps=1e-8,\n",
    "#     weight_decay=WD,\n",
    "# )\n",
    "\n",
    "criterion = SeesawLoss().cuda()\n",
    "# criterion = DiverseExpertLoss(SAMPLES_PER_CLS).cuda()\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53937ba-c14d-4e31-9edf-49ae8387964a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f633902-bc69-4b88-a4ae-e4e2f5a1f399",
   "metadata": {
    "tags": []
   },
   "source": [
    "## common_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90f80a5-179d-4517-91b5-68c79a2974a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def common_train(model, criterion, optimizer, data_loader, epochs):\n",
    "    \n",
    "    best_f1_score = 0\n",
    "    for epoch in range(epochs):\n",
    "        start=time.time()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_pred = []\n",
    "        train_y = []\n",
    "        train_f1 = 0\n",
    "\n",
    "        model.train()\n",
    "        for batch in tqdm(data_loader):\n",
    "            inputs = batch[0].cuda(non_blocking=True)\n",
    "            targets = batch[1].cuda(non_blocking=True)\n",
    "\n",
    "            # ------------- Common ------------------\n",
    "            optimizer.zero_grad()\n",
    "            with torch.cuda.amp.autocast():\n",
    "            # ---------------IB Loss ---------------------\n",
    "                if epoch >= IB_START_EPOCH:\n",
    "                    outputs, features = model(inputs)\n",
    "                    loss = criterion_ib((outputs, features), targets)\n",
    "                else:\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)#.mean()\n",
    "            # ---------------IB Loss ---------------------\n",
    "                # outputs = model(inputs)\n",
    "                # loss = criterion(outputs, targets)\n",
    "            # loss.backward()\n",
    "            # optimizer.step()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            # ------------- Common ------------------\n",
    "\n",
    "            # --------------- metric -------------------\n",
    "            # outs = []\n",
    "            # for k, v in outputs.items():\n",
    "            #     outs.append(outputs[k])\n",
    "            # outputs = torch.stack(outs, dim=1).mean(dim=1)\n",
    "            train_loss += loss.detach().cpu().item()/len(data_loader)\n",
    "            train_pred += outputs.argmax(1).detach().cpu().numpy().tolist()\n",
    "            train_y += targets.detach().cpu().numpy().tolist()\n",
    "            # --------------- metric -------------------\n",
    "\n",
    "        train_f1 = score_function(train_y, train_pred)\n",
    "\n",
    "        # ---------------IB Loss ---------------------\n",
    "        if epoch >= IB_START_EPOCH:\n",
    "            adjust_learning_rate(optimizer, epoch)\n",
    "        else:\n",
    "            scheduler.step()\n",
    "        # ---------------IB Loss ---------------------\n",
    "\n",
    "        if best_f1_score <= train_f1:\n",
    "            best_f1_score = train_f1\n",
    "            torch.save(model.state_dict(), MODEL_WEIGHT_NAME+\"_best.pt\")\n",
    "            print(\"model saved!\")\n",
    "            if best_f1_score == 1:\n",
    "                print(\"f1 score is 1!!\")\n",
    "                break\n",
    "        torch.save(model.state_dict(), MODEL_WEIGHT_NAME+\"_last.pt\")\n",
    "        print(\"last.pt saved!\")\n",
    "        \n",
    "        TIME = time.time() - start\n",
    "        print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "        print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583f878c-240c-4e53-a664-c3e65114ab29",
   "metadata": {
    "tags": []
   },
   "source": [
    "## finetune_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f116ba7-8b0a-40a2-9b4d-4c50077613e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_train(model, criterion, optimizer, scheduler, data_loader, epochs):\n",
    "        \n",
    "    best_f1_score = 0\n",
    "    for epoch in range(epochs):\n",
    "        start=time.time()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_pred = []\n",
    "        train_y = []\n",
    "        train_f1 = 0\n",
    "\n",
    "        model.train()\n",
    "        for batch in tqdm(data_loader):\n",
    "            x = batch[0].cuda(non_blocking=True)\n",
    "            y = batch[1].cuda(non_blocking=True)\n",
    "\n",
    "            # ---------------Common---------------------\n",
    "            optimizer.zero_grad()\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred = model(x)\n",
    "                loss = criterion(pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # ---------------Common----------------------\n",
    "            \n",
    "            # ----------------- SAM ---------------------\n",
    "#             # first forward-backward step\n",
    "#             enable_running_stats(model)\n",
    "#             with torch.cuda.amp.autocast():\n",
    "#                 pred = model(x)\n",
    "#                 loss = criterion(pred, y)\n",
    "#             loss.backward()\n",
    "#             optimizer.first_step(zero_grad=True)\n",
    "            \n",
    "#             # second forward-backward step\n",
    "#             disable_running_stats(model)\n",
    "#             with torch.cuda.amp.autocast():\n",
    "#                 second_loss = criterion(model(x), y)\n",
    "#             second_loss.backward()\n",
    "#             optimizer.second_step(zero_grad=True)\n",
    "            # ----------------- SAM ---------------------\n",
    "\n",
    "            # --------------- metric -------------------\n",
    "            train_loss += loss.detach().cpu().item()/len(data_loader)\n",
    "            train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "            train_y += y.detach().cpu().numpy().tolist()\n",
    "            # --------------- metric -------------------\n",
    "\n",
    "        train_f1 = score_function(train_y, train_pred)\n",
    "        scheduler.step()\n",
    "\n",
    "        if best_f1_score <= train_f1:\n",
    "            best_f1_score = train_f1\n",
    "            torch.save(model.state_dict(), MODEL_WEIGHT_NAME+\"_finetune_best.pt\")\n",
    "            print(\"best model saved!\")\n",
    "            if best_f1_score == 1:\n",
    "                print(\"f1 score is 1!!\")\n",
    "                break\n",
    "        torch.save(model.state_dict(), MODEL_WEIGHT_NAME+\"_finetune_last.pt\")\n",
    "        print(\"last model saved!\")\n",
    "        \n",
    "        TIME = time.time() - start\n",
    "        print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "        print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8034ff-ca7e-4218-8a7d-3c7bb236046b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## sam_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de732aec-6615-4348-a1da-8a813ab232f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sam_train(model, optimizer, data_loader, epochs, criterion=None):\n",
    "    best_f1_score = 0\n",
    "    for epoch in range(epochs):\n",
    "        start=time.time()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_pred = []\n",
    "        train_y = []\n",
    "        train_f1 = 0\n",
    "        \n",
    "        # idx = epoch // int(EPOCHS*0.8)\n",
    "        # betas = [0, 0.9999]\n",
    "        # effective_num = 1.0 - np.power(betas[idx], SAMPLES_PER_CLS)\n",
    "        # per_cls_weights = (1.0 - betas[idx]) / np.array(effective_num)\n",
    "        # per_cls_weights = per_cls_weights / np.sum(per_cls_weights) * len(SAMPLES_PER_CLS)\n",
    "        # per_cls_weights = torch.FloatTensor(per_cls_weights).cuda()\n",
    "        # criterion = LDAMLoss(cls_num_list=SAMPLES_PER_CLS, max_m=0.5, s=30, weight=per_cls_weights)\n",
    "        \n",
    "        model.train()\n",
    "        for batch in tqdm(data_loader):\n",
    "            inputs = batch[0].cuda(non_blocking=True)\n",
    "            targets = batch[1].cuda(non_blocking=True)\n",
    "\n",
    "            if epoch < MIXUP_END_EPOCH:\n",
    "                # --------------- MIXUP ------------------\n",
    "                inputs, targets_a, targets_b, lam = mixup_data(inputs, targets, MIXUP_ALPHA)\n",
    "                # --------------- MIXUP -----------------\n",
    "\n",
    "            # ---------------SAM---------------------\n",
    "            # first forward-backward step\n",
    "            enable_running_stats(model)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                if epoch < MIXUP_END_EPOCH:\n",
    "                    outputs, features = model(inputs)\n",
    "                    if epoch >= IB_START_EPOCH:\n",
    "                        loss = mixup_criterion(\"ib\", (outputs, features), targets_a, targets_b, lam)\n",
    "                    else:\n",
    "                        loss = mixup_criterion(\"cr\", outputs, targets_a, targets_b, lam)\n",
    "                else:\n",
    "                    # loss = criterion(outputs, targets)#.mean()\n",
    "                    # ---------------IB Loss ---------------------\n",
    "                    if epoch >= IB_START_EPOCH and IS_IB:\n",
    "                        outputs, features = model(inputs)\n",
    "                        loss = criterion_ib((outputs, features), targets)\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, targets)\n",
    "                    # ---------------IB Loss ---------------------\n",
    "            loss.backward()\n",
    "            # scaler.scale(loss).backward()\n",
    "            # scaler.unscale_(optimizer)\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            optimizer.first_step(zero_grad=True)\n",
    "            # scaler.step(optimizer)\n",
    "            # scaler.update()\n",
    "\n",
    "            # second forward-backward step\n",
    "            disable_running_stats(model)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                if epoch < MIXUP_END_EPOCH:\n",
    "                    if epoch >= IB_START_EPOCH and IS_IB:\n",
    "                        second_loss = mixup_criterion(\"ib\", model(inputs), targets_a, targets_b, lam)\n",
    "                    else:\n",
    "                        second_loss = mixup_criterion(\"cr\", model(inputs), targets_a, targets_b, lam)\n",
    "                else:\n",
    "                    # second_loss = criterion(model(inputs), targets)#.mean()\n",
    "                    # ---------------IB Loss ---------------------\n",
    "                    if epoch >= IB_START_EPOCH:\n",
    "                        second_loss = criterion_ib(model(inputs), targets)\n",
    "                    else:\n",
    "                        second_loss = criterion(model(inputs), targets)\n",
    "                    # ---------------IB Loss ---------------------\n",
    "            second_loss.backward()\n",
    "            # scaler.scale(second_loss).backward()\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            optimizer.second_step(zero_grad=True)\n",
    "\n",
    "            # mixup metric\n",
    "            if epoch < MIXUP_END_EPOCH:\n",
    "                _, pred = torch.max(outputs.data, 1)\n",
    "                correct = (lam * pred.eq(targets_a.data).cpu().sum().float()\n",
    "                            + (1 - lam) * pred.eq(targets_b.data).cpu().sum().float())\n",
    "            # ---------------SAM----------------------\n",
    "\n",
    "            # --------------- metric -------------------\n",
    "            train_loss += loss.detach().cpu().item()/len(data_loader)\n",
    "\n",
    "            if epoch < MIXUP_END_EPOCH:\n",
    "                train_correct += correct/len(data_loader)\n",
    "            else:\n",
    "                outs = []\n",
    "                for k, v in outputs.items():\n",
    "                    outs.append(outputs[k])\n",
    "                outputs = torch.stack(outs, dim=1).mean(dim=1)\n",
    "                train_pred += outputs.argmax(1).detach().cpu().numpy().tolist()\n",
    "                train_y += targets.detach().cpu().numpy().tolist()\n",
    "            # --------------- metric -------------------\n",
    "\n",
    "        if epoch >= MIXUP_END_EPOCH:\n",
    "            train_f1 = score_function(train_y, train_pred)\n",
    "\n",
    "        # ---------------IB Loss ---------------------\n",
    "        if epoch >= IB_START_EPOCH and IS_IB:\n",
    "            adjust_learning_rate(optimizer.base_optimizer, epoch)\n",
    "        else:\n",
    "            scheduler.step()\n",
    "        # ---------------IB Loss ---------------------\n",
    "\n",
    "        if best_f1_score <= train_f1:\n",
    "            best_f1_score = train_f1\n",
    "            torch.save(model.state_dict(), MODEL_WEIGHT_NAME+\"_best.pt\")\n",
    "            logging.debug(\"best model saved!\")\n",
    "            if best_f1_score == 1:\n",
    "                logging.debug(\"f1 score is 1!!\")\n",
    "                break\n",
    "\n",
    "        torch.save(model.state_dict(), MODEL_WEIGHT_NAME+\"_last.pt\")\n",
    "        logging.debug(\"last model saved!\")\n",
    "\n",
    "        TIME = time.time() - start\n",
    "        logging.debug(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "        if epoch < MIXUP_END_EPOCH:\n",
    "            logging.debug(f'TRAIN    loss : {train_loss:.5f}    accuracy : {train_correct:.5f}')\n",
    "        else:\n",
    "            logging.debug(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2daf23e-6496-4a86-a945-76d5aa1e0e3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Start Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba30339-2b1b-427c-9160-3b9170dab82b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "common_train(model=model, optimizer=optimizer, data_loader=train_loader, epochs=EPOCHS, criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171bf760-d7c3-4988-8cc6-1b3a3ad5b418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f4ccd4-26b6-4e1c-91c2-229c456eff5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2241024-d33e-4a2c-bb47-3d891d5388cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1eaecb-95ae-468f-9c36-c804b81b0f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(TEST_FILE)\n",
    "test_dataset = CustomDataset(df=test_df, mode=\"test\")\n",
    "test_loader = DataLoader(\n",
    "                    test_dataset,\n",
    "                    batch_size=BATCH,\n",
    "                    shuffle=False,\n",
    "                    pin_memory=True,\n",
    "                    num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f654652d-9f56-443e-8167-d120707c1d38",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90b8784-3ca4-4769-bbce-85e48bf64b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "tta_transform = tta.Compose(\n",
    "    [\n",
    "        # tta.HorizontalFlip(),\n",
    "        # tta.VerticalFlip(),\n",
    "        tta.Rotate90(angles=[0, 90, 180, 270]),\n",
    "        # tta.Scale(scales=[0.6, 0.8, 1]),\n",
    "        # tta.Multiply(factors=[0.9, 1, 1.1]),        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9dadd0-6362-4ab1-bf4c-aab8e5175f6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f9ba6c-ea8e-41ff-b4c9-e872f6fd4c77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Network(mode=\"test\")\n",
    "model.load_state_dict(torch.load(MODEL_WEIGHT_NAME+\"_best.pt\"))\n",
    "# model.load_state_dict(torch.load(\"tf_efficientnetv2_m_in21ft1k_120epochs_16batchsize_300imagesize_384testimagesize_0.0001lr_last.pt\"))\n",
    "model.to(DEVICE)\n",
    "print(\"Load \"+MODEL_WEIGHT_NAME)\n",
    "tta_model = tta.ClassificationTTAWrapper(model, tta_transform)\n",
    "\n",
    "model.eval()\n",
    "f_pred = []\n",
    "\n",
    "print(\"test image size:\", TEST_IMAGE_SIZE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        x = batch.cuda()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = tta_model(x)\n",
    "            # outputs = model(x)\n",
    "        f_pred.extend(outputs.argmax(1).detach().cpu().numpy().tolist())\n",
    "\n",
    "# Test labeling\n",
    "f_result = [LABEL_DECODER[result] for result in f_pred]\n",
    "\n",
    "# Submission\n",
    "submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "submission[\"label\"] = f_result\n",
    "submission.to_csv(SAVE_FILE_NAME, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
